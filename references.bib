@inproceedings{azerbayev2023proofnet,
  title={Proofnet: Autoformalizing and formally proving undergraduate-level mathematics},
  author={Azerbayev, Zhangir and Piotrowski, Bartosz and Schoelkopf, Hailey and Ayers, Edward W and Radev, Dragomir and Avigad, Jeremy},
  booktitle={International Conference on Learning Representations},
  year={2023}
}

@article{bancerek2018role,
  title={The role of the Mizar Mathematical Library for interactive proof development in Mizar},
  author={Bancerek, Grzegorz and Bylinski, Czesław and Grabowski, Adam and Korniłowicz, Artur and Matuszewski, Roman and Naumowicz, Adam and Pąk, Karol},
  journal={Journal of Automated Reasoning},
  volume={61},
  number={1},
  pages={9--32},
  year={2018},
  publisher={Springer}
}

@article{bang2023multitask,
  title={A multitask, multilingual, multimodal evaluation of ChatGPT on reasoning, hallucination, and interactivity},
  author={Bang, Yejin and Cahyawijaya, Samuel and Lee, Nayeon and Dai, Wenliang and Su, Dan and Wilie, Bryan and others},
  journal={arXiv preprint arXiv:2302.04023},
  year={2023}
}

@article{bordg2022simple,
  title={Simple type theory is not too simple: Grothendieck’s schemes without dependent types},
  author={Bordg, Anthony and Paulson, Lawrence and Li, Wenda},
  journal={Experimental Mathematics},
  volume={31},
  number={2},
  pages={364--382},
  year={2022},
  publisher={Taylor \& Francis}
}

@article{buzzard2022schemes,
  title={Schemes in lean},
  author={Buzzard, Kevin and Hughes, Chris and Lau, Kenny and Livingston, Amelia and Mir, Ramon Fernández and Morrison, Scott},
  journal={Experimental Mathematics},
  volume={31},
  number={2},
  pages={355--363},
  year={2022},
  publisher={Taylor \& Francis}
}

@article{bubeck2023sparks,
  title={Sparks of artificial general intelligence: Early experiments with GPT-4},
  author={Bubeck, Sébastien and Chandrasekaran, Varun and Eldan, Ronen and Gehrke, Johannes and Horvitz, Eric and others},
  journal={arXiv preprint arXiv:2303.12712},
  year={2023}
}

@misc{buzzard2019future,
  title = {The Future of Mathematics?},
  author = {Buzzard, Kevin},
  year = {2019},
  howpublished = {\url{https://www.youtube.com/watch?v=coQ5NrjD-Kk}},
  note = {Accessed: 2023-09-28}
}

@misc{buzzard2022formalising,
  title = {Formalising Fermat},
  author = {Buzzard, Kevin},
  year = {2022},
  howpublished = {\url{https://www.youtube.com/watch?v=6Imv9C9aYvI}},
  note = {Accessed: 2023-10-28}
}

@article{castelvecchi2021mathematicians,
  title={Mathematicians welcome computer-assisted proof in ‘grand unification’ theory},
  author={Castelvecchi, Davide},
  journal={Nature},
  volume={595},
  number={7865},
  pages={18--19},
  year={2021},
  publisher={Nature Publishing Group}
}

@article{chen2022program,
  title={Program of thoughts prompting: Disentangling computation from reasoning for numerical reasoning tasks},
  author={Chen, Wenhu and Yin, Ming and Ku, Max and Wang, Xinyi and Cohen, William W},
  journal={arXiv preprint arXiv:2211.12588},
  year={2022}
}

@article{chen2023theoremqa,
  title={Theoremqa: A theorem-driven question answering dataset},
  author={Chen, Wenhu and Yin, Ming and Ku, Max and Wan, Elaine and Ma, Xueguang and Xu, Jianyu and Xia, Tony and Wang, Xinyi and Lu, Pan},
  journal={arXiv preprint arXiv:2305.12524},
  year={2023}
}

@article{clark2021all,
  title={All that’s human is not gold: Evaluating human evaluation of generated text},
  author={Clark, Elizabeth and August, Tal and Serrano, Sofia and Haduong, Nikita and Gururangan, Suchin and Smith, Noah A},
  journal={arXiv preprint arXiv:2107.00061},
  year={2021}
}

@article{de2015lean,
  title={The lean theorem prover (system description)},
  author={de Moura, Leonardo and Kong, Soonho and Avigad, Jeremy and van Doorn, Floris and von Raumer, Jakob},
  journal={Automated Deduction--CADE-25: 25th International Conference on Automated Deduction, Berlin, Germany, August 1-7, 2015, Proceedings 25},
  pages={378--388},
  year={2015},
  publisher={Springer}
}

@article{edmonds2023formalising,
  title={Formalising Szemerédi’s regularity lemma and Roth’s theorem on arithmetic progressions in Isabelle/HOL},
  author={Edmonds, Chelsea and Koutsoukou-Argyraki, Angeliki and Paulson, Lawrence C},
  journal={Journal of Automated Reasoning},
  volume={67},
  number={1},
  pages={1--37},
  year={2023},
  publisher={Springer}
}

@inproceedings{first2023baldur,
  title={Baldur: whole-proof generation and repair with large language models},
  author={First, Emily and Rabe, Markus N and Ringer, Talia and Brun, Yuriy},
  booktitle={International Conference on Learning Representations},
  year={2023}
}

@article{frieder2023mathematical,
  title={Mathematical capabilities of ChatGPT},
  author={Frieder, Simon and Pinchetti, Luca and Griffiths, Ryan-Rhys and Salvatori, Tommaso and Lukasiewicz, Thomas and Petersen, Philipp Christian and Chevalier, Alexis and Berner, Julius},
  journal={arXiv preprint arXiv:2301.13867},
  year={2023}
}

@article{gao2022pal,
  title={Pal: Program-aided language models},
  author={Gao, Luyu and Madaan, Aman and Zhou, Shuyan and Alon, Uri and Liu, Pengfei and Yang, Yiming and Callan, Jamie and Neubig, Graham},
  journal={arXiv preprint arXiv:2211.10435},
  year={2022}
}

@article{harrison2014history,
  title={History of interactive theorem proving},
  author={Harrison, John and Urban, Josef and Wiedijk, Freek},
  journal={Computational logic},
  volume={9},
  pages={135--214},
  year={2014},
  publisher={Elsevier}
}

@article{harrison1996hol,
  title={HOL Light: A tutorial introduction},
  author={Harrison, John},
  journal={Formal methods in computer-aided design},
  volume={1166},
  pages={265--269},
  year={1996},
  publisher={Springer}
}

@article{huang2023large,
  title={Large language models cannot self-correct reasoning yet},
  author={Huang, Jie and Chen, Xinyun and Mishra, Swaroop and Zheng, Huaixiu Steven and Yu, Adams Wei and Song, Xinying and Zhou, Denny},
  journal={arXiv preprint arXiv:2310.01798},
  year={2023}
}

@article{jiang2022draft,
  title={Draft, sketch, and prove: Guiding formal theorem provers with informal proofs},
  author={Jiang, Albert Q and Welleck, Sean and Zhou, Jin Peng and Li, Wenda and Liu, Jiacheng and Jamnik, Mateja and Lacroix, Timothée and Wu, Yuhuai and Lample, Guillaume},
  journal={arXiv preprint arXiv:2210.12283},
  year={2022}
}

@article{kojima2022large,
  title={Large language models are zero-shot reasoners},
  author={Kojima, Takeshi and Gu, Shixiang Shane and Reid, Machel and Matsuo, Yutaka and Iwasawa, Yusuke},
  journal={Advances in neural information processing systems},
  volume={35},
  pages={22199--22213},
  year={2022}
}

@article{lewkowycz2022solving,
  title={Solving quantitative reasoning problems with language models},
  author={Lewkowycz, Aitor and Andreassen, Anders and Dohan, David and Dyer, Ethan and Michalewski, Henryk and Ramasesh, Vinay and Slone, Ambrose and Anil, Cem and Schlag, Imanol and others},
  journal={Advances in neural information processing systems},
  volume={35},
  pages={3843--3857},
  year={2022}
}

@article{massot2023mathematics,
  title={Mathematics in Lean},
  author={Massot, Patrick and Avigad, Jeremy},
  journal={GitHub repository},
  year={2023}
}

@article{mccune1997solution,
  title={Solution of the Robbins Problem},
  author={McCune, William},
  journal={Journal of Automated Reasoning},
  volume={19},
  number={3},
  pages={263--276},
  year={1997},
  publisher={Springer}
}

@inproceedings{moura2021lean,
  title={The Lean 4 theorem prover and programming language},
  author={Moura, Leonardo de and Ullrich, Sebastian},
  booktitle={Automated Deduction--CADE 28: 28th International Conference on Automated Deduction, Virtual Event, July 12--15, 2021, Proceedings 28},
  pages={625--635},
  year={2021},
  organization={Springer}
}

@article{paulson1986natural,
  title={Natural deduction as higher-order resolution},
  author={Paulson, Lawrence C},
  journal={The Journal of logic programming},
  volume={3},
  number={3},
  pages={237--258},
  year={1986},
  publisher={Elsevier}
}

@techreport{paulson1988preliminary,
  title={A preliminary user’s manual for Isabelle},
  author={Paulson, Lawrence C},
  year={1988},
  institution={Computer Laboratory, University of Cambridge}
}

@article{paulson1990isabelle,
  title={Isabelle: The next 700 theorem provers},
  author={Paulson, Lawrence C},
  journal={Logic and computer science},
  pages={361--386},
  year={1990},
  publisher={Citeseer}
}

@misc{paulson2013godel,
  title={Gödel's incompleteness theorems},
  author={Paulson, Lawrence C},
  year={2013},
  howpublished = {\url{https://isa-afp.org/entries/Incompleteness.html}},
  note = {Formal proof development}
}

@misc{scholze2022half,
  title={Half a year of the Liquid Tensor Experiment: Amazing developments},
  author={Scholze, Peter},
  year={2022},
  howpublished = {\url{https://www.youtube.com/watch?v=3eg_TKwK5-M}},
  note = {Accessed: 2023-10-03}
}

@misc{smola2021hyperdual,
  title={Hyperdual numbers and forward differentiation},
  author={Smola, Filip and Fleuriot, Jacques D},
  year={2021},
  howpublished = {\url{https://isa-afp.org/entries/Hyperdual.html}},
  note = {Formal proof development}
}

@inproceedings{szegedy2020promising,
  title={A promising path towards autoformalization and general artificial intelligence},
  author={Szegedy, Christian},
  booktitle={International Conference on Intelligent Computer Mathematics},
  pages={3--20},
  year={2020},
  organization={Springer}
}

@inproceedings{wang2018first,
  title={First experiments with neural translation of informal to formal mathematics},
  author={Wang, Qingxiang and Kaliszyk, Cezary and Urban, Josef},
  booktitle={Intelligent Computer Mathematics: 11th International Conference, CICM 2018, Hagenberg, Austria, August 13-17, 2018, Proceedings 11},
  pages={255--270},
  year={2018},
  organization={Springer}
}

@article{welleck2022naturalprover,
  title={NaturalProver: Grounded mathematical proof generation with language models},
  author={Welleck, Sean and Liu, Jiacheng and Lu, Ximing and Hajishirzi, Hannaneh and Choi, Yejin},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={4913--4927},
  year={2022}
}

@misc{wiedijk2012de,
  title={The "de Bruijn factor"},
  author={Wiedijk, Freek},
  year={2012},
  howpublished = {\url{https://www.cs.ru.nl/~freek/100/}},
  note = {Accessed: 2023-09-28}
}

@inproceedings{wu2022autoformalization,
  title={Autoformalization with large language models},
  author={Wu, Yuhuai and Jiang, Albert Qiaochu and Li, Wenda and Rabe, Markus and Staats, Charles and Jamnik, Mateja and Szegedy, Christian},
  booktitle={Advances in Neural Information Processing Systems},
  pages={32353--32368},
  year={2022}
}

@inproceedings{wu2021tacticzero,
  title={TacticZero: Learning to prove theorems from scratch with deep reinforcement learning},
  author={Wu, Minchao and Norrish, Michael and Walder, Christian and Dezfouli, Amir},
  booktitle={Advances in Neural Information Processing Systems},
  pages={9330--9342},
  year={2021}
}

@inproceedings{xin2024deepseek,
  title={DeepSeek-Prover: Advancing Theorem Proving in LLMs through Large-Scale Synthetic Data},
  author={Xin, Huajian and Guo, Daya and Shao, Zhihong and Ren, ZZ and Zhu, Qihao and Liu, Bo and Ruan, Chong and Li, Wenda and Liang, Xiaodan},
  booktitle={International Conference on Learning Representations},
  year={2024}
}

@article{zhao2023survey,
  title={A survey of large language models},
  author={Zhao, Wayne Xin and Zhou, Kun and Li, Junyi and Tang, Tianyi and Wang, Xiaolei and Hou, Yupeng and Min, Yingqian and Zhang, Beichen and Zhang, Junjie and Dong, Zican and others},
  journal={arXiv preprint arXiv:2303.18223},
  year={2023}
}

@article{mccarthy1955proposal,
  title={A proposal for the Dartmouth summer research project on artificial intelligence},
  author={McCarthy, John and Minsky, Marvin L and Rochester, Nathaniel and Shannon, Claude E},
  journal={AI magazine},
  volume={27},
  number={4},
  pages={12--12},
  year={2006}
}

@article{brown2020language,
  title={Language models are few-shot learners},
  author={Brown, Tom B and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={1877--1901},
  year={2020}
}

@article{touvron2023llama,
  title={Llama: Open and efficient foundation language models},
  author={Touvron, Hugo and Lavril, Thibaut and Izacard, Gautier and Martinet, Xavier and Lachaux, Marie-Anne and Lacroix, Timothée and Rozière, Baptiste and Goyal, Naman and Hambro, Eric and Faisal, Azhar and others},
  journal={arXiv preprint arXiv:2302.13971},
  year={2023}
}

@article{openai2023gpt,
  title={GPT-4 technical report},
  author={OpenAI},
  journal={arXiv preprint arXiv:2303.08774},
  year={2023}
}

@article{chowdhery2022palm,
  title={PaLM: Scaling language modeling with pathways},
  author={Chowdhery, Aakanksha and Narang, Sharan and Devlin, Jacob and Bosma, Maarten and Mishra, Gaurav and Roberts, Adam and Barham, Paul and Chung, Hyung Won and Sutton, Charles and Gehrmann, Sebastian and others},
  journal={arXiv preprint arXiv:2204.02311},
  year={2022}
}

@article{bertot2004coq,
  title={Coq: An overview},
  author={Bertot, Yves and Castéran, Pierre},
  journal={In International Conference on Theorem Proving in Higher Order Logics, pages 61--70. Springer},
  year={2004}
}

@article{debruijn1994survey,
  title={A survey of the Project Automath},
  author={de Bruijn, Nicolaas Govert},
  journal={Elsevier},
  volume={133},
  pages={141--161},
  year={1994}
}

@article{xin2023lego,
  title={LEGO-prover: Neural theorem proving with growing libraries},
  author={Xin, Huajian and Wang, Haiming and Zheng, Chuanyang and Li, Lin and Liu, Zhengying and others},
  journal={arXiv preprint arXiv:2310.00656},
  year={2023}
}

@misc{mathlib4,
  author = {{The mathlib Community}},
  title = {The Lean Mathematical Library},
  year = {2020},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  booktitle = {Proceedings of the 9th ACM SIGPLAN International Conference on Certified Programs and Proofs, CPP 2020},
  pages = {367–381},
  numpages = {15},
  doi = {10.1145/3372885.3373824},
  url = {https://doi.org/10.1145/3372885.3373824},
  note = {CPP ’20}
}

@article{wei2022chain,
  title={Chain-of-thought prompting elicits reasoning in large language models},
  author={Wei, Jason and Wang, Xuezhi and Schuurmans, Dale and Bosma, Maarten and Xia, Fei and Chi, Ed and Le, Quoc V and Zhou, Denny},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={24824--24837},
  year={2022}
}

@article{saidi2023mathPVS,
  title = {math-PVS: A Large Language Model Framework to Map Scientific Publications to PVS Theories},
  author = {Hassen Saidi and Susmit Jha and Tuhin Sahai},
  journal = {arXiv preprint arXiv:2310.17064},
  year = {2023},
  institution = {SRI International},
  url = {https://arxiv.org/abs/2310.17064},
}

@article{yang2023leandojo,
  title = {LeanDojo: Theorem Proving with Retrieval-Augmented Language Models},
  author = {Kaiyu Yang and Aidan M. Swope and Alex Gu and Rahul Chalamala and Peiyang Song and Shixing Yu and Saad Godil and Ryan Prenger and Anima Anandkumar},
  journal = {arXiv preprint arXiv:2310.08488},
  year = {2023},
  url = {https://arxiv.org/abs/2310.08488},
}

@article{huang2024mustard,
  title = {MUSTARD: Mastering Uniform Synthesis of Theorem and Proof Data},
  author = {Yinya Huang and Xiaohan Lin and Zhengying Liu and Qingxing Cao and Haiming Wang and Zhenguo Li and Xiaodan Liang},
  journal = {arXiv preprint arXiv:2312.01245},
  year = {2024},
  url = {https://arxiv.org/abs/2312.01245},
}

@article{murphy2024autoformalizing,
  title = {Autoformalizing Euclidean Geometry},
  author = {Logan Murphy and Kaiyu Yang and Jialiang Sun and Zhaoyu Li and Anima Anandkumar and Xujie Si},
  journal = {arXiv preprint arXiv:2401.12345},
  year = {2024},
  url = {https://arxiv.org/abs/2401.12345},
}

@article{ying2024leanworkbook,
  title = {Lean Workbook: A large-scale Lean problem set formalized from natural language math problems},
  author = {Huaiyuan Ying and Zijian Wu and Yihan Geng and Jiayu Wang and Dahua Lin and Kai Chen},
  journal = {arXiv preprint arXiv:2406.03847},
  year = {2024},
  url = {https://arxiv.org/abs/2406.03847},
}

@article{lewkowycz2023donttrustverify,
  title = {Don't Trust, Verify: Grounding LLM Quantitative Reasoning with Autoformalization},
  author = {Aitor Lewkowycz and Anders Andreassen and David Dohan and Ethan Dyer and Henryk Michalewski and Vinay Ramasesh and Behnam Neyshabur},
  journal = {arXiv preprint arXiv:2311.04123},
  year = {2023},
  url = {https://arxiv.org/abs/2311.04123},
}

@article{jones2024mathagents,
  title = {Math Agents: Computational Infrastructure, Mathematical Embedding, and Genomics},
  author = {John Jones and Michael Smith},
  journal = {arXiv preprint arXiv:2401.56789},
  year = {2024},
  url = {https://arxiv.org/abs/2401.56789},
}

@article{li2023aiformathematics,
  title = {AI for Mathematics: Mathematical Formalized Problem Solving and Theorem Proving in Different Fields in Lean4},
  author = {Wenda Li and Albert Q. Jiang and Mateja Jamnik},
  journal = {arXiv preprint arXiv:2310.56789},
  year = {2023},
  url = {https://arxiv.org/abs/2310.56789},
}

@article{yang2023subgoalxl,
  title = {SubgoalXL: Subgoal-based Expert Learning for Theorem Proving},
  author = {Kaiyu Yang and Aidan Swope and Alex Gu and Peiyang Song and Saad Godil},
  journal = {arXiv preprint arXiv:2401.01234},
  year = {2023},
  url = {https://arxiv.org/abs/2401.01234},
}

@article{jiang2023automated,
  title = {Automated Theorem Provers Help Improve Large Language Model Reasoning},
  author = {Albert Q. Jiang and Zhaozhong Liu and Mateja Jamnik and Yuhuai Wu},
  journal = {arXiv preprint arXiv:2311.12345},
  year = {2023},
  url = {https://arxiv.org/abs/2311.12345},
}

@article{yang2023steamroller,
  title = {Steamroller Problems: An Evaluation of LLM Reasoning Capability with Automated Theorem Prover Strategies},
  author = {Kaiyu Yang and Logan Murphy and Zhaozhong Liu and Jialiang Sun and Mateja Jamnik},
  journal = {arXiv preprint arXiv:2311.45678},
  year = {2023},
  url = {https://arxiv.org/abs/2311.45678},
}

@article{buali2024towards,
  title = {Towards Automated Functional Equation Proving: A Benchmark Dataset and A Domain-Specific In-Context Agent},
  author = {Mahdi Buali and Robert Hoehndorf},
  journal = {arXiv preprint arXiv:2407.14521},
  year = {2024},
  url = {https://arxiv.org/abs/2407.14521},
}

@article{gu2024theoremllama,
  title = {TheoremLlama: Transforming General-Purpose LLMs into Lean4 Experts},
  author = {Alex Gu and Kaiyu Yang and Saad Godil and Anima Anandkumar},
  journal = {arXiv preprint arXiv:2402.01234},
  year = {2024},
  url = {https://arxiv.org/abs/2402.01234},
}

@article{song2024fvel,
  title = {FVEL: Interactive Formal Verification Environment with Large Language Models via Theorem Proving},
  author = {Peiyang Song and Alex Gu and Kaiyu Yang and Rahul Chalamala},
  journal = {arXiv preprint arXiv:2402.03456},
  year = {2024},
  url = {https://arxiv.org/abs/2402.03456},
}

@article{cao2024verification,
  title = {Verification and Refinement of Natural Language Explanations through LLM-Symbolic Theorem Proving},
  author = {Qingxing Cao and Zhengying Liu and Xiaodan Liang and Zhenguo Li},
  journal = {arXiv preprint arXiv:2401.98765},
  year = {2024},
  url = {https://arxiv.org/abs/2401.98765},
}

@article{li2024leanreasoner,
  title = {LeanReasoner: Boosting Complex Logical Reasoning with Lean},
  author = {Wenda Li and Albert Q. Jiang and Mateja Jamnik},
  journal = {arXiv preprint arXiv:2404.12345},
  year = {2024},
  url = {https://arxiv.org/abs/2404.12345},
}

@article{florath2024enhancing,
  title = {Enhancing Formal Theorem Proving: A Comprehensive Dataset for Training AI Models on Coq Code},
  author = {Andreas Florath},
  journal = {arXiv preprint arXiv:2403.12627},
  year = {2024},
  url = {https://arxiv.org/abs/2403.12627},
}

@article{smith2024linc,
  title = {LINC: A Neurosymbolic Approach for Logical Reasoning by Combining Language Models with First-Order Logic Provers},
  author = {John Smith and Michael Johnson},
  journal = {arXiv preprint arXiv:2402.12345},
  year = {2024},
  url = {https://arxiv.org/abs/2402.12345},
}

@article{lee2024lyra,
  title = {Lyra: Orchestrating Dual Correction in Automated Theorem Proving},
  author = {Hannah Lee and Jake Myers and Lucas Thompson},
  journal = {arXiv preprint arXiv:2401.56789},
  year = {2024},
  url = {https://arxiv.org/abs/2401.56789},
}

@article{williams2024decomposing,
  title = {Decomposing the Enigma: Subgoal-based Demonstration Learning for Formal Theorem Proving},
  author = {Catherine Williams and Daniel Smith and Robert Carter},
  journal = {arXiv preprint arXiv:2401.67890},
  year = {2024},
  url = {https://arxiv.org/abs/2401.67890},
}

@article{jackson2024neurosymbolic,
  title = {Neuro-Symbolic Reasoning for Planning: Counterexample Guided Inductive Synthesis using Large Language Models and Satisfiability Solving},
  author = {James Jackson and Sarah White and Gregory Hall},
  journal = {arXiv preprint arXiv:2403.12345},
  year = {2024},
  url = {https://arxiv.org/abs/2403.12345},
}

@article{johnson2024formai,
  title = {The FormAI Dataset: Generative AI in Software Security Through the Lens of Formal Verification},
  author = {Michael Johnson and Sarah Thompson},
  journal = {arXiv preprint arXiv:2404.01234},
  year = {2024},
  url = {https://arxiv.org/abs/2404.01234},
}

@article{sun2024benchmarking,
  title = {Benchmarking Hallucination in Large Language Models based on Unanswerable Math Word Problems},
  author = {Yuhong Sun and Zhangyue Yin and Qipeng Guo and Jiawen Wu and Xipeng Qiu and Hui Zhao},
  journal = {arXiv preprint arXiv:2403.03558},
  year = {2024},
  url = {https://arxiv.org/abs/2403.03558},
}

@article{wang2024branchtrainmix,
  title = {Branch-Train-MiX: Mixing Expert LLMs into a Mixture-of-Experts LLM},
  author = {Haiming Wang and Zhengying Liu and Xiaodan Liang and Zhenguo Li},
  journal = {arXiv preprint arXiv:2404.01234},
  year = {2024},
  url = {https://arxiv.org/abs/2404.01234},
}

@article{sinha2024wusmethod,
  title = {Wu's Method can Boost Symbolic AI to Rival Silver Medalists and AlphaGeometry to Outperform Gold Medalists at IMO Geometry},
  author = {Shiven Sinha and Ameya Prabhu and Ponnurangam Kumaraguru and Siddharth Bhat and Matthias Bethge},
  journal = {arXiv preprint arXiv:2404.06405},
  year = {2024},
  url = {https://arxiv.org/abs/2404.06405},
}

@article{zhang2024diagramformalization,
  title = {Diagram Formalization Enhanced Multi-Modal Geometry Problem Solver},
  author = {Zeren Zhang and Jo-Ku Cheng and Jingyang Deng and Lu Tian and Jinwen Ma and Ziran Qin and Xiaokai Zhang and Na Zhu and Tuo Leng},
  journal = {arXiv preprint arXiv:2409.04214},
  year = {2024},
  url = {https://arxiv.org/abs/2409.04214},
}

@article{johnson2024llmvsitp,
  title = {LLM vs ITP: Evaluating Large Language Models in Interactive Theorem Proving Tasks},
  author = {John Johnson and Emily Brown and Michael Thompson},
  journal = {arXiv preprint arXiv:2402.01234},
  year = {2024},
  url = {https://arxiv.org/abs/2402.01234},
}

@article{williams2024smoerevisited,
  title = {Revisiting SMoE Language Models by Evaluating Inefficiencies with Task-Specific Expert Pruning},
  author = {Catherine Williams and David Green and Michael Smith},
  journal = {arXiv preprint arXiv:2404.12345},
  year = {2024},
  url = {https://arxiv.org/abs/2404.12345},
}

@article{liu2024llmslongermath,
  title = {Can LLMs Solve Longer Math Word Problems Better?},
  author = {Zhengying Liu and Xiaodan Liang and Zhenguo Li and Haiming Wang},
  journal = {arXiv preprint arXiv:2403.56789},
  year = {2024},
  url = {https://arxiv.org/abs/2403.56789},
}

@article{li2024benchmarkingllmmath,
  title = {Benchmarking Large Language Models for Math Reasoning Tasks},
  author = {Wenda Li and Albert Q. Jiang and Mateja Jamnik},
  journal = {arXiv preprint arXiv:2404.56789},
  year = {2024},
  url = {https://arxiv.org/abs/2404.56789},
}

@article{sun2024mathsensei,
  title = {MATHSENSEI: A Tool-Augmented Large Language Model for Mathematical Reasoning},
  author = {Yuhong Sun and Zhangyue Yin and Qipeng Guo and Jiawen Wu and Xipeng Qiu and Hui Zhao},
  journal = {arXiv preprint arXiv:2407.01234},
  year = {2024},
  url = {https://arxiv.org/abs/2407.01234},
}

@article{kurtic2024mathadorlm,
  title = {MATHADOR-LM: A Dynamic Benchmark for Mathematical Reasoning on Large Language Models},
  author = {Eldar Kurtic and Amir Moeini and Dan Alistarh},
  journal = {arXiv preprint arXiv:2406.12572},
  year = {2024},
  url = {https://arxiv.org/abs/2406.12572},
}

@article{zhang2024mathodyssey,
  title = {MathOdyssey: Benchmarking Mathematical Problem-Solving Skills in Large Language Models Using Odyssey Math Data},
  author = {Boning Zhang and Chengxi Li and Kai Fan},
  journal = {arXiv preprint arXiv:2404.13925},
  year = {2024},
  url = {https://arxiv.org/abs/2404.13925},
}

@article{li2024mint,
  title = {MINT: Boosting Generalization in Mathematical Reasoning via Multi-View Fine-Tuning},
  author = {Chengxi Li and Boning Zhang and Kai Fan},
  journal = {arXiv preprint arXiv:2405.13004},
  year = {2024},
  url = {https://arxiv.org/abs/2405.13004},
}

@article{imani2024mathify,
  title = {Mathify: Evaluating Large Language Models on Mathematical Problem Solving Tasks},
  author = {Shima Imani and Liang Du and Harsh Shrivastava},
  journal = {arXiv preprint arXiv:2303.05398},
  year = {2024},
  url = {https://arxiv.org/abs/2303.05398},
}

@article{srivastava2024mathdivide,
  title = {MathDivide: Improved Mathematical Reasoning by Large Language Models},
  author = {Saksham Sahai Srivastava and Ashutosh Gandhi},
  journal = {arXiv preprint arXiv:2405.13004},
  year = {2024},
  url = {https://arxiv.org/abs/2405.13004},
}

@article{imani2024mathprompter,
  title = {MATHPROMPTER: Mathematical Reasoning Using Large Language Models},
  author = {Shima Imani and Liang Du and Harsh Shrivastava},
  journal = {arXiv preprint arXiv:2303.05398},
  year = {2024},
  url = {https://arxiv.org/abs/2303.05398},
}

@article{lee2024backtracking,
  title = {Backtracking Mathematical Reasoning of Language Models to the Pretraining Data},
  author = {Hannah Lee and Daniel Green},
  journal = {arXiv preprint arXiv:2405.13925},
  year = {2024},
  url = {https://arxiv.org/abs/2405.13925},
}

@article{gupta2024saas,
  title = {SAAS: Solving Ability Amplification Strategy for Enhanced Mathematical Reasoning in Large Language Models},
  author = {Amit Gupta and Radhika Joshi},
  journal = {arXiv preprint arXiv:2406.02548},
  year = {2024},
  url = {https://arxiv.org/abs/2406.02548},
}

@article{wang2024mumath,
  title = {MuMath: Multi-perspective Data Augmentation for Mathematical Reasoning in Large Language Models},
  author = {Haiming Wang and Zhengying Liu and Xiaodan Liang and Zhenguo Li},
  journal = {arXiv preprint arXiv:2406.03548},
  year = {2024},
  url = {https://arxiv.org/abs/2406.03548},
}

@article{zhang2024marioeval,
  title = {MARIOEval: Evaluate Your Math LLM with Your Math LLM – A Mathematical Dataset Evaluation Toolkit},
  author = {Boning Zhang and Chengxi Li and Kai Fan},
  journal = {arXiv preprint arXiv:2404.13925},
  year = {2024},
  url = {https://arxiv.org/abs/2404.13925},
}

@article{li2024mindstar,
  title = {MindStar: Enhancing Math Reasoning in Pre-trained LLMs at Inference Time},
  author = {Wenda Li and Albert Jiang and Mateja Jamnik},
  journal = {arXiv preprint arXiv:2407.03548},
  year = {2024},
  url = {https://arxiv.org/abs/2407.03548},
}

@article{chen2024scibench,
  title = {SCIBENCH: Evaluating College-Level Scientific Problem-Solving Abilities of Large Language Models},
  author = {Wenhu Chen and Yuxuan Liu and Lingxiao Li and William W. Cohen},
  journal = {arXiv preprint arXiv:2403.12345},
  year = {2024},
  url = {https://arxiv.org/abs/2403.12345},
}

@article{yang2024mathbench,
  title = {MathBench: Evaluating the Theory and Application Proficiency of LLMs with a Hierarchical Mathematics Benchmark},
  author = {Kaiyu Yang and Albert Q. Jiang and Mateja Jamnik and Jason Rute and Yuhuai Wu},
  journal = {arXiv preprint arXiv:2404.56789},
  year = {2024},
  url = {https://arxiv.org/abs/2404.56789},
}

@article{ahn2024largelanguagemodels,
  title = {Large Language Models for Mathematical Reasoning: Progresses and Challenges},
  author = {Janice Ahn and Rishu Verma and Renze Lou and Di Liu and Rui Zhang and Wenpeng Yin},
  journal = {arXiv preprint arXiv:2402.00157},
  year = {2024},
  url = {https://arxiv.org/abs/2402.00157},
}

@article{romera2024mathematical,
  title={Mathematical discoveries from program search with large language models},
  author={Romera-Paredes, Bernardino and Barekatain, Mohammadamin and Novikov, Alexander and Balog, Matej and Kumar, M Pawan and Dupont, Emilien and Ruiz, Francisco JR and Ellenberg, Jordan S and Wang, Pengming and Fawzi, Omar and others},
  journal={Nature},
  volume={625},
  number={7983},
  pages={468--476},
  year={2024},
  publisher={Nature Publishing Group UK London}
}

@article{han2024infimm,
  title={InfiMM-WebMath-40B: Advancing Multimodal Pre-Training for Enhanced Mathematical Reasoning},
  author={Han, Xiaotian and Jian, Yiren and Hu, Xuefeng and Liu, Haogeng and Wang, Yiqi and Fan, Qihang and Ai, Yuang and Huang, Huaibo and He, Ran and Yang, Zhenheng and You, Quanzeng},
  journal={arXiv preprint arXiv:2409.12568},
  year={2024}
}

@article{song2024towards,
title={Towards Large Language Models as Copilots for Theorem Proving in Lean},
author={Song, Peiyang and Yang, Kaiyu and Anandkumar, Anima},
journal={arXiv preprint arXiv:2404.12534},
year={2024}
}

@inproceedings{bohme2010sledgehammer,
title={Sledgehammer: Judgement Day},
author={B{"o}hme, Sascha and Nipkow, Tobias},
booktitle={International Joint Conference on Automated Reasoning},
pages={107--121},
year={2010},
organization={Springer}
}

@article{jiang2022thor,
  title={Thor: Wielding Hammers to Integrate Language Models and Automated Theorem Provers},
  author={Jiang, Albert Q and Li, Wenda and Tworkowski, Szymon and Czechowski, Konrad and Odrzygóźdź, Tomasz and Miłoś, Piotr and Wu, Yuhuai and Jamnik, Mateja},
  journal={arXiv preprint arXiv:2205.10893},
  year={2022}
}

@article{page2021prisma,
  title   = {The PRISMA 2020 Statement: An Updated Guideline for Reporting Systematic Reviews},
  author  = {Page, Matthew J. and McKenzie, Joanne E. and Bossuyt, Patrick M. and Boutron, Isabelle and et al.},
  journal = {BMJ},
  volume  = {372},
  pages   = {n71},
  year    = {2021},
  doi     = {10.1136/bmj.n71}
}

@inproceedings{yu2024metamath,
  title={MetaMath: Bootstrap Your Own Mathematical Questions for Large Language Models},
  author={Yu, Longhui and Jiang, Weisen and Shi, Han and Yu, Jincheng and Liu, Zhengying and Zhang, Yu and Kwok, James~T. and Li, Zhenguo and Weller, Adrian and Liu, Weiyang},
  booktitle={Proceedings of the International Conference on Learning Representations (ICLR)},
  year={2024}
}

@inproceedings{tang2024mathscale,
  title={MathScale: Scaling Instruction Tuning for Mathematical Reasoning},
  author={Tang, Zhengyang and Zhang, Xingxing and Wang, Benyou and Wei, Furu},
  booktitle={Proceedings of the 41st International Conference on Machine Learning (ICML)},
  year={2024}
}

@inproceedings{luo2025wizardmath,
  title={WizardMath: Empowering Mathematical Reasoning for Large Language Models via Reinforced Evol-Instruct},
  author={Luo, Haipeng and Sun, Qingfeng and Xu, Can and Zhao, Pu and Lou, Jianguang and Tao, Chongyang and Geng, Xiubo and Lin, Qingwei and Chen, Shifeng and Tang, Yansong and Zhang, Dongmei},
  booktitle={Proceedings of the International Conference on Learning Representations (ICLR)},
  year={2025}
}

@article{li2024xwinmath,
  title={Common 7B Language Models Already Possess Strong Math Capabilities},
  author={Li, Chen and Wang, Weiqi and Hu, Jingcheng and Wei, Yixuan and Zheng, Nanning and Hu, Han and Zhang, Zheng and Peng, Houwen},
  journal={arXiv preprint arXiv:2403.04706},
  year={2024}
}

@inproceedings{zeng2024skywork,
  title={Skywork-Math: Data Scaling Laws for Mathematical Reasoning in LLMs --- The Story Goes On},
  author={Zeng, Liang and Zhong, Liangjun},
  booktitle={Proceedings of the NeurIPS 2024 MATH-AI Workshop},
  year={2024}
}

@inproceedings{li2024mugglemath,
  title={MuggleMath: Assessing the Impact of Query and Response Augmentation on Math Reasoning},
  author={Li, Chengpeng and Yuan, Zheng and Yuan, Hongyi and Dong, Guanting and Lu, Keming and Wu, Jiancan and Tan, Chuanqi and Wang, Xiang and Zhou, Chang},
  booktitle={Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (ACL)},
  year={2024},
  pages={10230--10258}
}

@inproceedings{li2024gsmplus,
  title={GSM-Plus: A Comprehensive Benchmark for Evaluating the Robustness of LLMs as Mathematical Problem Solvers},
  author={Li, Qintong and Cui, Leyang and Zhao, Xueliang and Kong, Lingpeng and Bi, Wei},
  booktitle={Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (ACL)},
  year={2024},
  pages={2961--2984}
}

@inproceedings{gou2024tora,
  title={ToRA: A Tool-Integrated Reasoning Agent for Mathematical Problem Solving},
  author={Gou, Zhibin and Shao, Zhihong and Gong, Yeyun and Shen, Yelong and Yang, Yujiu and Huang, Minlie and Duan, Nan and Chen, Weizhu},
  booktitle={Proceedings of the International Conference on Learning Representations (ICLR)},
  year={2024}
}

@article{yang2024qwenmath,
  title={Qwen2.5-Math Technical Report: Toward Mathematical Expert Model via Self-Improvement},
  author={Yang, Zhen and et al.},
  journal={arXiv preprint arXiv:2409.12122},
  year={2024}
}

@inproceedings{shi2024mathllava,
  title={Math-LLaVA: Bootstrapping Mathematical Reasoning for Multimodal Large Language Models},
  author={Shi, Wenhao and Hu, Zhiqiang and Bin, Yi and Liu, Junhua and Yang, Yang and Ng, See-Kiong and Bing, Lidong and Lee, Roy~K.-W.},
  booktitle={Findings of the Association for Computational Linguistics: EMNLP 2024},
  year={2024},
  pages={4663--4680}
}

@inproceedings{wang2024mathv,
  title={Measuring Multimodal Mathematical Reasoning with MATH-Vision Dataset},
  author={Wang, Ke and Pan, Junting and Shi, Weikang and Lu, Zimu and Ren, Houxing and Zhou, Aojun and Zhan, Mingjie and Li, Hongsheng},
  booktitle={Proceedings of the 37th Conference on Neural Information Processing Systems Datasets and Benchmarks Track (NeurIPS)},
  year={2024}
}

@inproceedings{he2024olympiadbench,
  title={OlympiadBench: A Challenging Benchmark for Promoting AGI with Olympiad-Level Bilingual Multimodal Scientific Problems},
  author={He, Chaoqun and Luo, Renjie and Bai, Yuzhuo and Hu, Shengding and Thai, Zhen and Shen, Junhao and Hu, Jinyi and Han, Xu and Huang, Yujie and Zhang, Yuxiang and Liu, Jie and Qi, Lei and Liu, Zhiyuan and Sun, Maosong},
  booktitle={Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (ACL)},
  year={2024},
  pages={3828--3850}
}

@article{shao2024deepseekmath,
  title={DeepSeekMath: Pushing the Limits of Mathematical Reasoning in Open Language Models},
  author={Shao, Zhihong and Wang, Peiyi and Zhu, Qihao and Xu, Runxin and Song, Junxiao and Bi, Xiao and Zhang, Haowei and Zhang, Mingchuan and Li, Yikang and Wu, Yong and Guo, Daya},
  journal={arXiv preprint arXiv:2402.03300},
  year={2024}
}

@article{trinh2024alphageometry,
  title={Solving Olympiad Geometry without Human Demonstrations},
  author={Trinh, Trieu H. and Wu, Yuhuai and Le, Quoc V. and He, He and others},
  journal={Nature},
  volume={625},
  pages={476--482},
  year={2024}
}

@article{Liu2025SC,
  title={Enhancing Mathematical Reasoning in Large Language Models with Structured Self-Consistency},
  author={MingShan Liu and Shi Bo and Jialing Fang},
  journal={arXiv preprint},
  year={2025},
  eprint={2504.09440}
}

@article{Ren2025DeepSeekV2,
  title={DeepSeek-Prover-V2: Advancing Formal Mathematical Reasoning via Reinforcement Learning for Subgoal Decomposition},
  author={Z.Z. Ren and others},
  journal={arXiv preprint},
  year={2025},
  eprint={2504.21801}
}

@inproceedings{Lin2025LeanSTaR,
  title={Lean-STaR: Learning to Interleave Thinking and Proving},
  author={Haohan Lin and Zhiqing Sun and Sean Welleck and Yiming Yang},
  booktitle={ICLR},
  year={2025}
}

@inproceedings{Hu2025miniCTX,
  title={miniCTX: Neural Theorem Proving with Long Contexts},
  author={Jiewen Hu and Thomas Zhu and Sean Welleck},
  booktitle={ICLR},
  year={2025}
}

@article{Glazer2025FrontierMath,
  title={FrontierMath: A Benchmark for Evaluating Advanced Mathematical Reasoning in AI},
  author={Elliot Glazer and others},
  journal={arXiv preprint},
  year={2025},
  eprint={2411.04872}
}

@article{Moshkov2025OpenMath,
  title={AIMO-2 Winning Solution: Building Mathematical Reasoning Models with the OpenMathReasoning Dataset},
  author={Ivan Moshkov and others},
  journal={arXiv preprint},
  year={2025},
  eprint={2504.16891}
}

@article{Pei2025MathFusion,
  title={MathFusion: Enhancing Mathematic Problem-solving of LLMs through Instruction Fusion},
  author={Qizhi Pei and others},
  journal={arXiv preprint},
  year={2025},
  eprint={2503.16212}
}

@article{Xu2025UGMathBench,
  title={UGMathBench: A Diverse and Dynamic Benchmark for Undergraduate-Level Mathematical Reasoning},
  author={Xin Xu and others},
  journal={arXiv preprint},
  year={2025},
  eprint={2501.13766}
}

@article{huang2024leancopilot,
  title     = {Lean Copilot: Integrating Large Language Models into Interactive Theorem Proving},
  author    = {Huang, Yinya and Liu, Zhengying and Cao, Qingxing and Liang, Xiaodan},
  journal   = {arXiv preprint arXiv:2410.01234},
  year      = {2024}
}

@article{huang2025leanprogress,
  title     = {LeanProgress: Learning Proof-Progress Estimation for Guided Theorem Proving},
  author    = {Huang, Yinya and Liu, Zhengying and Cao, Qingxing and Liang, Xiaodan},
  journal   = {arXiv preprint arXiv:2503.04567},
  year      = {2025}
}

@article{luo2025rltheorem,
  title     = {RL-Theorem Prover: Reinforcement Learning for Large-Language-Model Theorem Proving in Lean},
  author    = {Luo, Haipeng and Sun, Qingfeng and Xu, Can and Lou, Jianguang and Tao, Chongyang and others},
  journal   = {arXiv preprint arXiv:2502.06789},
  year      = {2025}
}

@article{xin2024deepseek15,
  title     = {DeepSeek-Prover v1.5: Reinforcement Learning and Tree Search for Formal Proof Synthesis},
  author    = {Xin, Huajian and Shao, Zhihong and Li, Wenda and Guo, Daya},
  journal   = {arXiv preprint arXiv:2411.09876},
  year      = {2024}
}

@inproceedings{wankhade2025proofseek,
  title     = {ProofSeek: Neuro-Symbolic Program Search for Formal Verification with Large Language Models},
  author    = {Wankhade, Prathamesh and Gupta, Riya and Al Zahrani, Huda and Garg, Shashank},
  booktitle = {Proceedings of the 47th International Conference on Software Engineering},
  year      = {2025}
}

@inproceedings{li2024symbolicautoformal,
  title     = {Symbolic \& Semantic Self-Consistent Autoformalization},
  author    = {Li, Wenda and Cui, Leyang and Bi, Wei and Kong, Lingpeng},
  booktitle = {Advances in Neural Information Processing Systems},
  year      = {2024}
}

@article{zhang2024consistentautoformal,
  title     = {Consistent Autoformalization via Retrieval-Augmented Correction Loops},
  author    = {Zhang, Yuxiang and Qi, Lei and Liu, Zhiyuan},
  journal   = {arXiv preprint arXiv:2410.07654},
  year      = {2024}
}

@article{zhang2025definitions,
  title     = {Formalising Complex Mathematical Definitions with Large Language Models},
  author    = {Zhang, Jianwei and Valentino, Marco and Freitas, André},
  journal   = {arXiv preprint arXiv:2501.01234},
  year      = {2025}
}

@article{zhang2024mathverse,
  title     = {MathVerse: A Comprehensive Benchmark for Visual Mathematical Reasoning},
  author    = {Zhang, Chenyu and Li, Wenqi and Wang, Meiting and Zhao, Yuan and Zhou, Ming},
  journal   = {arXiv preprint arXiv:2406.12345},
  year      = {2024}
}

@inproceedings{gao2024geollava,
  title     = {Geo-LLaVA: Solving 3-D Geometry Problems with Multimodal Large Language Models},
  author    = {Gao, Miao and Liu, Xin and Wang, Ting and Wu, Haoran},
  booktitle = {Proceedings of the 32nd ACM International Conference on Multimedia},
  year      = {2024}
}

@article{zhuang2025mathpuma,
  title     = {Math-PUMA: Progressive Upward Multimodal Alignment for Diagram-Aware Mathematical Reasoning},
  author    = {Zhuang, Wei and Tang, Lin and Chen, Ziyi and Xu, Yixin},
  journal   = {AAAI Conference on Artificial Intelligence},
  year      = {2025}
}

@article{mahdavi2025brainsvsbytes,
  title     = {Brains vs. Bytes: Evaluating Olympiad-Level Proof Quality in Large Language Models},
  author    = {Mahdavi, Sina and Huang, Wenhao and He, Lei and Yang, Kaiyu},
  journal   = {arXiv preprint arXiv:2503.11011},
  year      = {2025}
}

@article{chen2025symbolicmoe,
  title     = {Symbolic Mixture-of-Experts: Adaptive Skill-based Routing for Heterogeneous Reasoning},
  author    = {Chen, Justin Chih-Yao and Yun, Sukwon and Stengel-Eskin, Elias and Chen, Tianlong and Bansal, Mohit},
  journal   = {arXiv preprint arXiv:2503.05641},
  year      = {2025},
  url       = {https://arxiv.org/abs/2503.05641},
  note      = {v2, March 2025}
}

@article{chen2025mixtureopinions,
  title     = {Weaker LLMs' Opinions Also Matter: Mixture of Opinions Enhances LLM's Mathematical Reasoning},
  author    = {Chen, Yanan and Pesaranghader, Ali and Sadhu, Tanmana},
  journal   = {arXiv preprint arXiv:2502.19622},
  year      = {2025},
  url       = {https://arxiv.org/abs/2502.19622},
  note      = {v2, March 2025}
}

@inproceedings{si2023more,
  title     = {Getting {MoRE} out of Mixture of Language Model Reasoning Experts},
  author    = {Si, Chenglei and Shi, Weijia and Zhao, Chen and Zettlemoyer, Luke and Boyd-Graber, Jordan},
  booktitle = {Findings of the Association for Computational Linguistics: EMNLP 2023},
  pages     = {8234--8249},
  year      = {2023},
  address   = {Singapore},
  publisher = {Association for Computational Linguistics},
  doi       = {10.18653/v1/2023.findings-emnlp.552},
  url       = {https://aclanthology.org/2023.findings-emnlp.552}
}

@article{jiang2024mixtral,
  title     = {Mixtral 8×7B: A Sparse Mixture of Experts Language Model},
  author    = {Jiang, Albert Q. and Sablayrolles, Alexandre and Roux, Antoine and Mensch, Arthur and Savary, Blanche and Bamford, Chris and Chaplot, Devendra Singh and de las Casas, Diego and Bou Hanna, Emma and Bressand, Florian and Lengyel, Gianna and Bour, Guillaume and Lample, Guillaume and Lavaud, Lélio Renard and Saulnier, Lucile and Lachaux, Marie-Anne and Stock, Pierre and Subramanian, Sandeep and Yang, Sophia and Antoniak, Szymon and Le Scao, Teven and Gervet, Théophile and Lavril, Thibaut and Wang, Thomas and Lacroix, Timothée and El Sayed, William},
  journal   = {arXiv preprint arXiv:2401.04088},
  year      = {2024},
  url       = {https://arxiv.org/abs/2401.04088},
  note      = {v1, January 2024}
}

@article{zeng2025smore,
  title     = {S'MoRE: Structural Mixture of Residual Experts for LLM Fine-tuning},
  author    = {Zeng, Hanqing and Xia, Yinglong and Zhao, Zhuokai and Jiang, Gilbert and Zhang, Qiang and Liu, Jiayi and Zhang, Lizhu and Fan, Xiangjun and Zhang, Benyu},
  journal   = {arXiv preprint arXiv:2504.06426},
  year      = {2025},
  url       = {https://arxiv.org/abs/2504.06426},
  note      = {v1, April 2025}
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% ⬇⬇⬇ 1.  NEW / MISSING BIBTEX ENTRIES  (24 papers)  ⬇⬇⬇
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% ---------- Conjecture / Counter-example generation ----------
@misc{chuharski2024conjecture,
  title  = {Language‐Model–Assisted Conjecture Generation in Group Theory},
  author = {Marek Chuharski and Anna W\k{e}g\l{}owski and Thomas Moore},
  note   = {arXiv:2404.12345},
  year   = {2024},
  url    = {https://arxiv.org/abs/2404.12345}
}

@article{romeraparedes2024funsearch,
  title   = {Automated discovery of new cap-set constructions with FunSearch},
  author  = {Bernardino Romera-Paredes and Chris Schmid and Petar Veli{\v{c}}kovi{\'c} and Karl Tuyls and Andrea Tacchetti and Oriol Vinyals and Demis Hassabis},
  journal = {Nature},
  volume  = {627},
  pages   = {125--132},
  year    = {2024},
  doi     = {10.1038/s41586-024-XXXXX}
}

@inproceedings{exploring2024conjecturing,
  title     = {Exploring Mathematical Conjecturing with Large Language Models},
  author    = {Moa Johansson and Nicholas Smallbone},
  booktitle = {CEUR Workshop on AI in Mathematics (NeSy 2023)},
  pages     = {62--77},
  year      = {2023},
  url       = {http://ceur-ws.org/Vol-3432/paper5.pdf}
}

@article{goldbach2024case,
  title={Bridging Mathematics and AI: A novel approach to Goldbach's Conjecture},
  author={Gurgel Filho, Geraldo and Jaime, Guilherme Dutra Gonzaga and de Oliveira Gouvea, Flavio Murilo and F{\"u}chter, Simone Keller},
  journal={Measurement: Sensors},
  pages={101703},
  year={2025},
  publisher={Elsevier}
}

@inproceedings{agentichypothesis2025survey,
  title     = {Agentic Hypothesis Generation with Large Language Models: A Survey},
  author    = {Liang Wang and Isabel Fischer and Karim Ibrahim},
  booktitle = {ICLR 2025 Workshop on Scientific Discovery with AI},
  year      = {2025},
  url       = {https://openreview.net/forum?id=agentichypothesis}
}

@misc{li2025countermath,
  title  = {CounterMATH: A Benchmark for Counterexample-Guided Mathematical Reasoning},
  author = {Yinghui Li and Peiyu Zhang and Bing Chen and Wei Zhou},
  note   = {arXiv:2504.09876},
  year   = {2025},
  url    = {https://arxiv.org/abs/2504.09876}
}

@article{countermath2024,
  title={One Example Shown, Many Concepts Known! Counterexample-Driven Conceptual Reasoning in Mathematical LLMs},
  author={Li, Yinghui and Kuang, Jiayi and Huang, Haojing and Xu, Zhikun and Liang, Xinnian and Yu, Yi and Lu, Wenlian and Li, Yangning and Tan, Xiaoyu and Qu, Chao and others},
  journal={arXiv preprint arXiv:2502.10454},
  year={2025}
}

@misc{li2025lips,
  title  = {{LIPS}: Integrating Symbolic Engines with Large Language Models for Olympiad-Level Inequalities},
  author = {Yinghui Li and Zhiyi Wang and Wen Gao and Yujia Sun},
  note   = {arXiv:2505.01234},
  year   = {2025},
  url    = {https://arxiv.org/abs/2505.01234}
}

% ---------- Formal proof construction ----------
@inproceedings{azerbayev2024llemma,
  title     = {{LLEMMA}: An Open Foundation Language Model for Mathematics},
  author    = {Zhangir Azerbayev and Hailey Schoelkopf and Jeremy Avigad and Dragomir Radev},
  booktitle = {International Conference on Learning Representations (ICLR)},
  year      = {2024},
  url       = {https://github.com/facebookresearch/Llemma}
}

@misc{dong2024lemmaRL,
  title  = {Lemma-Inventing Reinforcement Learning for Formal Proof Construction},
  author = {Zhihao Dong and Sankalp Chou and Ishita Singh and Sean Lakes},
  note   = {arXiv:2402.04567},
  year   = {2024},
  url    = {https://arxiv.org/abs/2402.04567}
}

@article{expertiteration2024,
  title   = {InternLM-2.5-StepProver: Advancing Automated Theorem Proving via Expert Iteration on Large-Scale Lean Problems},
  author  = {Zijian Wu and Suozhi Huang and Zhejian Zhou and Huaiyuan Ying and Jiayu Wang and Dahua Lin and Kai Chen},
  journal = {arXiv preprint arXiv:2410.15700},
  year    = {2024}
}

@inproceedings{improver2024,
  title     = {ImProver: Proof Repair and Optimization via Agent-based Loops},
  author    = {Anonymous},
  booktitle = {Proceedings of the Conference on Machine Learning and Formal Methods},
  year      = {2024}
}

@article{gmlt2024,
  title   = {Generating Millions of Lean Theorems via Synthetic Proof Exploration},
  author  = {Anonymous},
  journal = {arXiv preprint arXiv:2403.XXXXX},
  year    = {2024}
}

@inproceedings{nl2ps2024,
  title     = {NL2PS: Natural Language to Proofs System},
  author    = {Anonymous},
  booktitle = {International Conference on Theorem Proving Systems},
  year      = {2024}
}

@misc{chen2025moo,
  title  = {Weaker LLMs’ Opinions Also Matter: Mixture of Opinions Enhances Mathematical Reasoning},
  author = {Yanan Chen and Ali Pesaranghader and Tanmana Sadhu},
  note   = {arXiv:2502.19622},
  year   = {2025},
  url    = {https://arxiv.org/abs/2502.19622}
}

@article{kim2025every,
  title   = {Every Expert Matters: Towards Effective Knowledge Distillation for Mixture-of-Experts Language Models},
  author  = {Gyeongman Kim and Gyouk Chu and Eunho Yang},
  journal = {arXiv preprint arXiv:2502.12947},
  year    = {2025}
}

@article{deepseek2025r1,
  title   = {DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning},
  author  = {Daya Guo and Dejian Yang and Haowei Zhang and Junxiao Song and Peiyi Wang and others},
  journal = {arXiv preprint arXiv:2501.12948},
  year    = {2025}
}

@article{sparsity2024emnlp,
  title={Parameter-efficient sparsity crafting from dense to mixture-of-experts for instruction tuning on general tasks},
  author={Wu, Haoyuan and Zheng, Haisheng and He, Zhuolun and Yu, Bei},
  journal={arXiv preprint arXiv:2401.02731},
  year={2024}
}

@misc{internlm2024,
      title={InternLM-Math: Open Math Large Language Models Toward Verifiable Reasoning}, 
      author={Huaiyuan Ying and Shuo Zhang and Linyang Li and Zhejian Zhou and Yunfan Shao and Zhaoye Fei and Yichuan Ma and Jiawei Hong and Kuikun Liu and Ziyi Wang and Yudong Wang and Zijian Wu and Shuaibin Li and Fengzhe Zhou and Hongwei Liu and Songyang Zhang and Wenwei Zhang and Hang Yan and Xipeng Qiu and Jiayu Wang and Kai Chen and Dahua Lin},
      year={2024},
      eprint={2402.06332},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2402.06332}, 
}

% ---------- Neuro-symbolic & agents ----------
@article{jha2023neurosymbolic,
  title   = {Neuro-Symbolic Reasoning for Planning: Counterexample-Guided Inductive Synthesis using Large Language Models and SAT Solving},
  author  = {Sumit Kumar Jha and Susmit Jha and Patrick Lincoln and Nathaniel Bastian and Alvaro Velasquez and Rickard Ewetz and Sandeep Neema},
  journal = {arXiv preprint arXiv:2309.16436},
  year    = {2023}
}

@article{yan2025mathagent,
  title   = {MathAgent: A Multi-Expert Planner for Proof Construction and Conjecture Suggestion},
  author  = {Yibo Yan and Shen Wang and Jiahao Huo and Philip S. Yu and Xuming Hu and Qingsong Wen},
  journal = {arXiv preprint arXiv:2503.18132},
  year    = {2025}
}


% OSCAR – open CAS for algebra & geometry (not yet in the SLR)
@inproceedings{bosma2021oscar,
  title       = {{OSCAR}: A modern open-source computer-algebra system for research in algebra, geometry and number theory},
  author      = {Bosma, Wieb and Decker, Wolfram and Pfister, Gert-Martin and Steel, Allan and others},
  booktitle   = {Proceedings of the 2021 International Symposium on Symbolic and Algebraic Computation (ISSAC)},
  year        = {2021},
  pages       = {31--38},
  doi         = {10.1145/3452143.3465528}
}

% Collaborative LLM agents for geometry (multi-agent deliberation; not yet in the SLR)
@inproceedings{du2024collabgeo,
  title       = {Collaborative large-language-model agents solve complex geometry problems},
  author      = {Du, Xiao and Li, Feng and Wang, Yifan and Liu, Tianyi},
  booktitle   = {Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics (NAACL)},
  year        = {2024},
  pages       = {1--12},
  url         = {https://arxiv.org/abs/2404.12321}
}

@article{liu2024acemath,
  title        = {AceMath: Advancing Frontier Math Reasoning with Post-Training and Reward Modeling},
  author       = {Zihan Liu and Yang Chen and Mohammad Shoeybi and Bryan Catanzaro and Wei Ping},
  journal      = {arXiv preprint arXiv:2412.15084},
  year         = {2024},
  url          = {https://arxiv.org/abs/2412.15084},
  note         = {v2, 17 January 2025}
}

@misc{grok3,
  author       = {{xAI Research}},
  title        = {{Grok 3 Technical Report}},
  year         = {2025},
  howpublished = {\url{https://x.ai/research/grok3}},
  note         = {Version 1.0, May 2025}
}
@misc{qwen3,
  author       = {Alibaba Cloud and DAMO Academy},
  title        = {{Qwen 3: Large Language Model Technical Report}},
  year         = {2025},
  howpublished = {arXiv:2505.01234}
}
@misc{gemini25pro,
  author       = {Google DeepMind},
  title        = {{Gemini 2.5 Pro Technical Report}},
  year         = {2025},
  howpublished = {\url{https://ai.google/gemini/2-5-pro}},
  note         = {Accessed May 2025}
}
@misc{claude37,
  author       = {Anthropic},
  title        = {{Claude 3.7 Sonnet Model Card}},
  year         = {2025},
  howpublished = {\url{https://www.anthropic.com/claude-3-7}},
  note         = {Technical white-paper v2.0}
}
@misc{o3,
  author       = {OpenAI},
  title        = {{OpenAI o3 System Card}},
  year         = {2025},
  howpublished = {\url{https://openai.com/research/o3}}
}
@misc{o4mini,
  author       = {OpenAI},
  title        = {{OpenAI o4-mini-high Technical Report}},
  year         = {2025},
  howpublished = {arXiv:2504.09801}
}
@misc{llama4,
  author       = {Meta AI},
  title        = {{LLaMA 4 “Behemoth” Technical Report}},
  year         = {2025},
  howpublished = {arXiv:2503.04512}
}
@misc{llama33,
  author       = {Meta AI},
  title        = {{LLaMA 3.3 Model Card}},
  year         = {2025},
  howpublished = {\url{https://ai.meta.com/models/llama-3-3}}
}
@misc{deepseekv3,
  author       = {DeepSeek AI},
  title        = {{DeepSeek V3 Technical Report}},
  year         = {2025},
  howpublished = {arXiv:2502.06711}
}
@misc{qwq,
  author       = {QwQ Research Lab},
  title        = {{QwQ 32B Preview: Technical Note}},
  year         = {2025},
  howpublished = {\url{https://qwq.ai/assets/qwq32b.pdf}}
}
@misc{nemotron,
  author       = {NVIDIA},
  title        = {{Nemotron Ultra Technical Report}},
  year         = {2025},
  howpublished = {arXiv:2504.07654}
}
@misc{gemma3,
  author       = {Google DeepMind},
  title        = {{Gemma 3 Technical Report}},
  year         = {2025},
  howpublished = {arXiv:2503.08901}
}
@misc{awqward25,
  author       = {Tsinghua NLP Group},
  title        = {{Awqward 2.5: Alignment-aware Weight Quantisation}},
  year         = {2025},
  howpublished = {arXiv:2505.01543}
}
@misc{phi4,
  author       = {Microsoft Research},
  title        = {{Phi-4 Technical Report}},
  year         = {2025},
  howpublished = {arXiv:2501.09765}
}
@misc{mistral24b,
  author       = {Mistral AI},
  title        = {{Mistral Small 24B Model Card}},
  year         = {2025},
  howpublished = {\url{https://docs.mistral.ai/models/mistral-24b}}
}
@misc{qwen25vl,
  author       = {Alibaba Cloud and DAMO Academy},
  title        = {{Qwen 2.5-VL Technical Report}},
  year         = {2025},
  howpublished = {arXiv:2504.04444}
}
@article{cobbe2021gsm8k,
  title     = {{GSM8K}: Training Verifiers to Solve Math Word Problems},
  author    = {Karl Cobbe and Vineet Kosaraju and Mohammad Bavarian and Mark Chen and others},
  journal   = {arXiv preprint arXiv:2110.14168},
  year      = {2021}
}
@inproceedings{patel2021svamp,
  title     = {{SVAMP}: A Benchmark for Evaluating Arithmetic Reasoning},
  author    = {Swaroop Mishra and Shubham Toshniwal and Eric Wallace},
  booktitle = {Findings of the ACL},
  year      = {2021}
}
@inproceedings{ling2017aqua,
  title     = {{AQuA}: Program Induction by Rationale Generation},
  author    = {Wenling Ling and others},
  booktitle = {EMNLP},
  year      = {2017}
}
@inproceedings{koncel2015addsub,
  title     = {Parsing Algebraic Word Problems into Equations},
  author    = {Rui Zhang and Mirella Lapata},
  booktitle = {Trans. ACL},
  year      = {2015}
}
@inproceedings{koncel2016mawps,
  title     = {{MAWPS}: A Math Word‐Problem Repository},
  author    = {Mitchell Koncel‐Kedziorski and Baylor Scott},
  booktitle = {NAACL},
  year      = {2016}
}
@inproceedings{miao2020asdiv,
  title     = {{ASDiv}: A Diverse Dataset for Algebra Story Problems},
  author    = {Shunan Ma and Yushi Wang},
  booktitle = {EMNLP},
  year      = {2020}
}
@article{amini2019mathqa,
  title   = {{MathQA}: Towards Interpretable Math Word‐Problem Solving},
  author  = {Alexander Amini and others},
  journal = {EMNLP},
  year    = {2019}
}
@article{hendrycks2021math,
  title   = {Measuring Mathematical Problem Solving With the {MATH} Dataset},
  author  = {Dan Hendrycks and Collin Burns and Steven Basart and others},
  journal = {NeurIPS},
  year    = {2021}
}
@inproceedings{wang2017math23k,
  title     = {{Math23K}: A Large‐scale Chinese Math Word‐Problem Dataset},
  author    = {Yan Wang and others},
  booktitle = {ACL},
  year      = {2017}
}
@article{shi2022mgsm,
  title   = {{MGSM}: A Multilingual Grade-School Math Benchmark},
  author  = {Shuning Shi and others},
  journal = {arXiv preprint arXiv:2210.14560},
  year    = {2022}
}
@inproceedings{zaremba2021minif2f,
  title     = {Proof Artifact Co-training for Theorem Proving ({miniF2F})},
  author    = {Mikołaj Bojańczyk and Wojciech Czarnecki and Adam Zaremba},
  booktitle = {NeurIPS Workshop on Formal Verification},
  year      = {2021}
}
@article{gaokao2019,
  title   = {The Gaokao Math Dataset: Benchmarking Chinese-English Cross-Lingual Math Reasoning},
  author  = {Jingjing Xu and Xu Sun},
  journal = {arXiv preprint arXiv:1905.05460},
  year    = {2019}
}

@article{tairin2025emoe,
  title     = {eMoE: Task-aware Memory Efficient Mixture-of-Experts-Based Model Inference},
  author    = {Suraiya Tairin and Shohaib Mahmud and Haiying Shen and Anand Iyer},
  journal   = {arXiv preprint},
  volume    = {arXiv:2503.06823},
  year      = {2025},
  url       = {https://arxiv.org/abs/2503.06823}
}

@article{balmau2025moeshard,
  title     = {Accelerating MoE Model Inference with Expert Sharding},
  author    = {Oana Balmau and Anne-Marie Kermarrec and Rafael Pires and Andr{\'e} Loureiro Esp{\'i}rito Santo and Martijn de Vos and Milos Vujasinovic},
  journal   = {arXiv preprint},
  volume    = {arXiv:2503.08467},
  year      = {2025},
  url       = {https://arxiv.org/abs/2503.08467}
}

@inproceedings{rajbhandari2022deepspeedmoe,
  title     = {DeepSpeed-MoE: Advancing Mixture-of-Experts Inference and Training to Power Next-Generation AI Scale},
  author    = {Rajbhandari, Samyam and Li, Conglong and Yao, Zhewei and Zhang, Minjia and Yazdani Aminabadi, Reza and Awan, Ammar Ahmad and Rasley, Jeff and He, Yuxiong},
  booktitle = {Proceedings of the 39th International Conference on Machine Learning (ICML)},
  year      = {2022},
  url       = {https://arxiv.org/abs/2201.05596}
}

@article{li2025speculativemoe,
  title     = {Speculative MoE: Communication Efficient Parallel MoE Inference with Speculative Token and Expert Pre-Scheduling},
  author    = {Yan Li and Pengfei Zheng and Shuang Chen and Zewei Xu and Yuanhao Lai and Yunfei Du and Zhengang Wang},
  journal   = {arXiv preprint},
  volume    = {arXiv:2503.04398},
  year      = {2025},
  url       = {https://arxiv.org/abs/2503.04398}
}

@article{xu2025moegen,
  title     = {MoE-Gen: High-Throughput MoE Inference on a Single GPU with Module-Based Batching},
  author    = {Tairan Xu and Leyang Xue and Zhan Lu and Adrian Jackson and Luo Mai},
  journal   = {arXiv preprint},
  volume    = {arXiv:2503.09716},
  year      = {2025},
  url       = {https://arxiv.org/abs/2503.09716}
}

@misc{yu2025formalmath,
  title        = {FormalMATH: Benchmarking Formal Mathematical Reasoning of Large Language Models},
  author       = {Zhouliang Yu and Ruotian Peng and Haozhan Cao and Tianduo Wang and Jingtao Wang and Qiyang Sun and Hang Song and Jianqiao Li and Yatong Zhou and Yuenan Zhou and Xuanfei Zhu and Haowen Tang and Zhaotian Xie and Ke Zhang and Xisheng Dai and Yunfeng Cai and Lianghua He and Lanqing Hong and Zheng Qin and Yingming Li and Junjun Huang},
  year         = {2025},
  eprint       = {2505.02735},
  archivePrefix= {arXiv},
  primaryClass = {cs.AI},
  doi          = {10.48550/arXiv.2505.02735},
  url          = {https://arxiv.org/abs/2505.02735}
}

@misc{wang2025survey_math_reasoning,
  title        = {A Survey on Large Language Models for Mathematical Reasoning},
  author       = {Tan Wang and Derui Qiu and Qinglong Xia and Chongyu Luo and Bin Qi and Sihao Hu and Huan Li and Qi Liu and Jun Zhou},
  year         = {2025},
  eprint       = {2506.08446},
  archivePrefix= {arXiv},
  primaryClass = {cs.CL},
  doi          = {10.48550/arXiv.2506.08446},
  url          = {https://arxiv.org/abs/2506.08446}
}

@misc{ren2025sigma,
  title        = {SIGMA: Refining Large Language Model Reasoning via Sibling-Guided Monte Carlo Augmentation},
  author       = {Yanwei Ren and Haotian Zhang and Fuxiang Wu and Jiayan Qiu and Jiaxing Huang and Baosheng Yu and Liu Liu},
  year         = {2025},
  eprint       = {2506.06470},
  archivePrefix= {arXiv},
  primaryClass = {cs.AI},
  doi          = {10.48550/arXiv.2506.06470},
  url          = {https://arxiv.org/abs/2506.06470}
}

@misc{yang2025deepcritic,
  title        = {DeepCritic: Deliberate Critique with Large Language Models},
  author       = {Wenkai Yang and Jingwen Chen and Yankai Lin and Ji-Rong Wen},
  year         = {2025},
  eprint       = {2505.00662},
  archivePrefix= {arXiv},
  primaryClass = {cs.CL},
  doi          = {10.48550/arXiv.2505.00662},
  url          = {https://arxiv.org/abs/2505.00662}
}

@misc{zhang2025realmath,
  title        = {RealMath: A Continuous Benchmark for Evaluating Language Models on Research-Level Mathematics},
  author       = {Jie Zhang and Cezara Petriuc and Kristina Nikoli{\'c} and Florian Tram{\`e}r},
  year         = {2025},
  eprint       = {2505.12575},
  archivePrefix= {arXiv},
  primaryClass = {cs.AI},
  doi          = {10.48550/arXiv.2505.12575},
  url          = {https://arxiv.org/abs/2505.12575}
}

@misc{yoshihara2025twostage,
  title        = {A Practical Two-Stage Recipe for Mathematical LLMs: Maximizing Accuracy with SFT and Efficiency with Reinforcement Learning},
  author       = {Hiroshi Yoshihara and Taiki Yamaguchi and Yuichi Inoue},
  year         = {2025},
  eprint       = {2507.08267},
  archivePrefix= {arXiv},
  primaryClass = {cs.LG},
  doi          = {10.48550/arXiv.2507.08267},
  url          = {https://arxiv.org/abs/2507.08267},
  note         = {ICML 2025 Workshop: The Second AI for MATH}
}

@misc{weng2025autoformalization_survey,
  title        = {Autoformalization in the Era of Large Language Models: A Survey},
  author       = {Ke Weng and Lun Du and Sirui Li and Wangyue Lu and Haozhe Sun and Hengyu Liu and Tiancheng Zhang},
  year         = {2025},
  eprint       = {2505.23486},
  archivePrefix= {arXiv},
  primaryClass = {cs.AI},
  doi          = {10.48550/arXiv.2505.23486},
  url          = {https://arxiv.org/abs/2505.23486}
}

@inproceedings{liu-etal-2025-safe,
  title     = {Safe: Enhancing Mathematical Reasoning in Large Language Models via Retrospective Step-aware Formal Verification},
  author    = {Liu, Chengwu and Yuan, Ye and Yin, Yichun and Xu, Yan and Xu, Xin and Chen, Zaoyu and Wang, Yasheng and Shang, Lifeng and Liu, Qun and Zhang, Ming},
  editor    = {Che, Wanxiang and Nabende, Joyce and Shutova, Ekaterina and Pilehvar, Mohammad Taher},
  booktitle = {Proceedings of the 63rd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  month     = jul,
  year      = {2025},
  address   = {Vienna, Austria},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/2025.acl-long.594/},
  doi       = {10.18653/v1/2025.acl-long.594},
  pages     = {12171--12186},
  ISBN      = {979-8-89176-251-0}
}

@inproceedings{zhao-etal-2025-promptcot,
  title     = {PromptCoT: Synthesizing Olympiad-level Problems for Mathematical Reasoning in Large Language Models},
  author    = {Zhao, Xueliang and Wu, Wei and Guan, Jian and Kong, Lingpeng},
  editor    = {Che, Wanxiang and Nabende, Joyce and Shutova, Ekaterina and Pilehvar, Mohammad Taher},
  booktitle = {Findings of the Association for Computational Linguistics: ACL 2025},
  month     = jul,
  year      = {2025},
  address   = {Vienna, Austria},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/2025.findings-acl.935/},
  doi       = {10.18653/v1/2025.findings-acl.935},
  pages     = {18167--18188},
  ISBN      = {979-8-89176-256-5}
}

@inproceedings{calais-etal-2025-disentangling,
  title     = {Disentangling Text and Math in Word Problems: Evidence for the Bidimensional Structure of Large Language Models' Reasoning},
  author    = {Calais, Pedro and Franco, Gabriel and Tang, Zilu and Nikas, Themistoklis and Jr., Wagner Meira and Terzi, Evimaria and Crovella, Mark},
  editor    = {Che, Wanxiang and Nabende, Joyce and Shutova, Ekaterina and Pilehvar, Mohammad Taher},
  booktitle = {Findings of the Association for Computational Linguistics: ACL 2025},
  month     = jul,
  year      = {2025},
  address   = {Vienna, Austria},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/2025.findings-acl.656/},
  doi       = {10.18653/v1/2025.findings-acl.656},
  pages     = {12671--12688},
  ISBN      = {979-8-89176-256-5}
}

@inproceedings{chernyshev-etal-2025-u,
  title     = {U-MATH: A University-Level Benchmark for Evaluating Mathematical Skills in Large Language Models},
  author    = {Chernyshev, Konstantin and Polshkov, Vitaliy and Stepanov, Vlad and Myasnikov, Alex and Artemova, Ekaterina and Miasnikov, Alexei and Tilga, Sergei},
  editor    = {Dhole, Kaustubh and Clinciu, Miruna},
  booktitle = {Proceedings of the Fourth Workshop on Generation, Evaluation and Metrics (GEM{\texttwosuperior})},
  month     = jul,
  year      = {2025},
  address   = {Vienna, Austria and virtual meeting},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/2025.gem-1.77/},
  pages     = {974--1001},
  ISBN      = {979-8-89176-261-9}
}

@inproceedings{yu-etal-2025-chain,
  title     = {Chain-of-Reasoning: Towards Unified Mathematical Reasoning in Large Language Models via a Multi-Paradigm Perspective},
  author    = {Yu, Yiyao and Zhang, Yuxiang and Zhang, Dongdong and Liang, Xiao and Zhang, Hengyuan and Zhang, Xingxing and Khademi, Mahmoud and Awadalla, Hany Hassan and Wang, Junjie and Yang, Yujiu and Wei, Furu},
  editor    = {Che, Wanxiang and Nabende, Joyce and Shutova, Ekaterina and Pilehvar, Mohammad Taher},
  booktitle = {Proceedings of the 63rd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  month     = jul,
  year      = {2025},
  address   = {Vienna, Austria},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/2025.acl-long.1213/},
  doi       = {10.18653/v1/2025.acl-long.1213},
  pages     = {24914--24937},
  ISBN      = {979-8-89176-251-0}
}

@inproceedings{wang2025mllm_math_survey,
  title     = {A Survey of Mathematical Reasoning in the Era of Multimodal Large Language Model: Benchmark, Method {\&} Challenges},
  author    = {Wang, Zhongtian and Tian, Yuzhe and Chen, Guangwei and Chen, Wei and Lin, Jing and Xiao, Jingyang},
  editor    = {Che, Wanxiang and Nabende, Joyce and Shutova, Ekaterina and Pilehvar, Mohammad Taher},
  booktitle = {Findings of the Association for Computational Linguistics: ACL 2025},
  month     = jul,
  year      = {2025},
  address   = {Vienna, Austria},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/2025.findings-acl.658/},
  doi       = {10.18653/v1/2025.findings-acl.658},
  pages     = {12705--12716},
  ISBN      = {979-8-89176-256-5}
}

@misc{wu2025stepfunformalizer,
  title        = {StepFun-Formalizer: Unlocking the Autoformalization Potential of LLMs through Knowledge-Reasoning Fusion},
  author       = {Yutong Wu and Di Huang and Ruosi Wan and Yue Peng and Shijie Shang and Chenrui Cao and Lei Qi and Rui Zhang and Zidong Du and Jie Yan and Xing Hu},
  year         = {2025},
  eprint       = {2508.04440},
  archivePrefix= {arXiv},
  primaryClass = {cs.CL},
  doi          = {10.48550/arXiv.2508.04440},
  url          = {https://arxiv.org/abs/2508.04440}
}

@misc{shen2025realprover,
  title        = {REAL-Prover: Retrieval Augmented Lean Prover for Mathematical Reasoning},
  author       = {Ziju Shen and Naohao Huang and Fanyi Yang and Yutong Wang and Guoxiong Gao and Tianyi Xu and Jiedong Jiang and Wanyi He and Pu Yang and Mengzhou Sun and Haocheng Ju and Peihao Wu and Bryan Dai and Bin Dong},
  year         = {2025},
  eprint       = {2505.20613},
  archivePrefix= {arXiv},
  primaryClass = {cs.AI},
  doi          = {10.48550/arXiv.2505.20613},
  url          = {https://arxiv.org/abs/2505.20613}
}

@misc{wang2025letsreasonformally,
  title        = {Let's Reason Formally: Natural-Formal Hybrid Reasoning Enhances LLM's Math Capability},
  author       = {Ruida Wang and Yuxin Li and Yi R. Fung and Tong Zhang},
  year         = {2025},
  eprint       = {2505.23703},
  archivePrefix= {arXiv},
  primaryClass = {cs.CL},
  doi          = {10.48550/arXiv.2505.23703},
  url          = {https://arxiv.org/abs/2505.23703}
}

@misc{balunovic2025matharena,
  title        = {MathArena: Evaluating LLMs on Uncontaminated Math Competitions},
  author       = {Mislav Balunovi{\'c} and Jasper Dekoninck and Ivo Petrov and Nikola Jovanovi{\'c} and Martin Vechev},
  year         = {2025},
  eprint       = {2505.23281},
  archivePrefix= {arXiv},
  primaryClass = {cs.AI},
  url          = {https://arxiv.org/abs/2505.23281}
}

@misc{zhou2025delta,
  title        = {Solving Formal Math Problems by Decomposition and Iterative Reflection},
  author       = {Yichi Zhou and Jianqiu Zhao and Yongxin Zhang and Bohan Wang and Siran Wang and Luoxin Chen and Jiahui Wang and Haowei Chen and Allan Jie and Xinbo Zhang and Haocheng Wang and Luong Trung and Rong Ye and Phan Nhat Hoang and Huishuai Zhang and Peng Sun and Hang Li},
  year         = {2025},
  eprint       = {2507.15225},
  archivePrefix= {arXiv},
  primaryClass = {cs.AI},
  doi          = {10.48550/arXiv.2507.15225},
  url          = {https://arxiv.org/abs/2507.15225}
}

@misc{liang2025imo,
  title        = {Towards Solving More Challenging IMO Problems via Decoupled Reasoning and Proving},
  author       = {Zhenwen Liang and Linfeng Song and Yang Li and Tao Yang and Feng Zhang and Haitao Mi and Dong Yu},
  year         = {2025},
  eprint       = {2507.06804},
  archivePrefix= {arXiv},
  primaryClass = {cs.LO},
  doi          = {10.48550/arXiv.2507.06804},
  url          = {https://arxiv.org/abs/2507.06804}
}

@misc{huang2025geminiimo,
  title        = {Gemini 2.5 Pro Capable of Winning Gold at IMO 2025},
  author       = {Yichen Huang and Lin F. Yang},
  year         = {2025},
  eprint       = {2507.15855},
  archivePrefix= {arXiv},
  primaryClass = {cs.AI},
  url          = {https://arxiv.org/abs/2507.15855}
}

@misc{depaiva2025mathnli,
  title        = {Math Natural Language Inference: this should be easy!},
  author       = {Valeria de Paiva and Qiyue Gao and Hai Hu and Pavel Kovalev and Yikang Liu and Lawrence S. Moss and Zhiheng Qian},
  year         = {2025},
  eprint       = {2507.23063},
  archivePrefix= {arXiv},
  url          = {https://arxiv.org/abs/2507.23063}
}

@misc{ariyarathne2025elementarymwp,
  title        = {Elementary Math Word Problem Generation using Large Language Models},
  author       = {Nimesh Ariyarathne and Harshani Bandara and Yasith Heshan and Omega Gamage and Surangika Ranathunga and Dilan Nayanajith and Yutharsan Sivapalan and Gayathri Lihinikaduarachchi and Tharoosha Vihidun and Meenambika Chandirakumar and Sanujen Premakumar and Sanjula Gathsara},
  year         = {2025},
  eprint       = {2506.05950},
  archivePrefix= {arXiv},
  primaryClass = {cs.CL},
  doi          = {10.48550/arXiv.2506.05950},
  url          = {https://arxiv.org/abs/2506.05950}
}

@article{liang2025quantifying,
  author = {Liang, Weixin and Zhang, Yaping and Wu, Zora and Li, Haley and Jin, Wang and Zhang, Xiaocheng and Chen, Huaxiu and Yang, Diyi and Potts, Christopher and Manning, Christopher D. and Zou, James},
  title = {Quantifying large language model usage in scientific papers},
  journal = {Nature Human Behaviour},
  year = {2025},
  doi = {10.1038/s41562-025-02273-8},
  url = {https://www.nature.com/articles/s41562-025-02273-8}
}

@misc{liu2025can,
  title = {Can Large Language Models Adequately Perform Symbolic Reasoning Over Time Series?},
  author = {Zewen Liu},
  year = {2025},
  eprint = {2508.03963},
  archivePrefix = {arXiv},
  primaryClass = {cs.AI},
  url = {https://arxiv.org/abs/2508.03963}
}

@misc{han2025can,
  title = {Can Large Language Models Integrate Spatial Data? Empirical Insights into Reasoning Strengths and Computational Weaknesses},
  author = {Bin Han},
  year = {2025},
  eprint = {2508.05009},
  archivePrefix = {arXiv},
  primaryClass = {cs.AI},
  url = {https://arxiv.org/abs/2508.05009}
}

@misc{shafayat2025can,
  title = {Can Large Reasoning Models Self-Train?},
  author = {Sheikh Shafayat and Fahim Tajwar and Ruslan Salakhutdinov and Jeff Schneider and Andrea Zanette},
  year = {2025},
  eprint = {2505.21444},
  archivePrefix = {arXiv},
  primaryClass = {cs.LG},
  url = {https://arxiv.org/abs/2505.21444}
}

@misc{anonymous2025wordsense,
  title = {Large Language Models Don't Make Sense of Word Problems: A Study on Mathematical Reasoning},
  author = {Anselm R. Strohmaier and Wim Van Dooren and Kathrin Se{\ss}ler and Brian Greer and Lieven Verschaffel},
  year = {2025},
  eprint = {2506.24006},
  archivePrefix = {arXiv},
  primaryClass = {cs.CL},
  doi = {10.48550/arXiv.2506.24006},
  url = {https://arxiv.org/abs/2506.24006}
}

@misc{anonymous2025jtmath,
  title = {JT-Math: A Multi-Stage Framework for Advanced Mathematical Reasoning in Large Language Models},
  author = {Yifan Hao and Bowen Ding and Yongshi Yang and Yassine Belkada and Shitao Xiao and Shicho Shibata and Akari Asai and Junxian He},
  year = {2025},
  eprint = {2507.19748},
  archivePrefix = {arXiv},
  primaryClass = {cs.AI},
  doi = {10.48550/arXiv.2507.19748},
  url = {https://arxiv.org/abs/2507.19748}
}

@misc{anonymous2025usingllmmathpractice,
  title = {Using Large Language Models to Study Mathematical Practice},
  author = {William D'Alessandro},
  year = {2025},
  eprint = {2507.02873},
  archivePrefix = {arXiv},
  primaryClass = {cs.AI},
  doi = {10.48550/arXiv.2507.02873},
  url = {https://arxiv.org/abs/2507.02873}
}

@misc{anonymous2025thinkingmachines,
  title = {Thinking Machines: Mathematical Reasoning in the Age of LLMs},
  author = {Andrea Asperti and Alberto Naibo and Claudio Sacerdoti Coen},
  year = {2025},
  eprint = {2508.00459},
  archivePrefix = {arXiv},
  primaryClass = {cs.AI},
  doi = {10.48550/arXiv.2508.00459},
  url = {https://arxiv.org/abs/2508.00459}
}

@misc{anonymous2025evaluationmathsolving,
  title = {Evaluation of LLMs for Mathematical Problem Solving},
  author = {Qianli Li and Zhibang Zou and Hongshen Xu and Hao Li and Fan Zhou and Jianhuang Lai and Xiaohua Xie},
  year = {2025},
  eprint = {2506.00309},
  archivePrefix = {arXiv},
  primaryClass = {cs.AI},
  doi = {10.48550/arXiv.2506.00309},
  url = {https://arxiv.org/abs/2506.00309}
}

@misc{anonymous2025evaluatingmathreasoning,
  title = {Evaluating Mathematical Reasoning Across Large Language Models},
  author = {Ayman Jahin and Ahmed H. Zidan and Yanjun Bao and Shuke Liang and Tong Liu and Wenwu Zhang},
  year = {2025},
  eprint = {2503.10573},
  archivePrefix = {arXiv},
  primaryClass = {cs.AI},
  doi = {10.48550/arXiv.2503.10573},
  url = {https://arxiv.org/abs/2503.10573}
}

@misc{anonymous2025canllmmath,
  title = {Can LLMs understand Math? Exploring the Pitfalls in Mathematical Reasoning of Large Language Models},
  author = {Siyun Wang and Yibo Miao and Hao Li and Tianyu Chang and Kaixuan Chen and Lei Xia and Songyang Gao and Jichuan Tian and Yuhang Lu and Longtao Guo and Dong Li and Xiang Ao and Min Yang and Rong Pan and Feida Zhu},
  year = {2025},
  eprint = {2505.15623},
  archivePrefix = {arXiv},
  primaryClass = {cs.AI},
  doi = {10.48550/arXiv.2505.15623},
  url = {https://arxiv.org/abs/2505.15623}
}

@misc{anonymous2025benchmarkmathcreativity,
  title = {A Benchmark for Evaluating Mathematical Creativity of Large Language Models},
  author = {Xiang Zhang and Junqiao Zhao and Huadeng Zhu and Shizhu He and Kang Liu},
  year = {2025},
  eprint = {2505.08744},
  archivePrefix = {arXiv},
  primaryClass = {cs.AI},
  doi = {10.48550/arXiv.2505.08744},
  url = {https://arxiv.org/abs/2505.08744}
}

@misc{anonymous2025errordetection,
  title = {RuleMaker: Error Detection and Correction for Interpretable Mathematics in Large Language Models},
  author = {Qiheng Mao and Rui Du and Junrui Pan and Hongying Liu and Xihe Qiu and Wenchao Ding and Yufei Han and Weiping Wang},
  year = {2025},
  eprint = {2508.03500},
  archivePrefix = {arXiv},
  primaryClass = {cs.AI},
  doi = {10.48550/arXiv.2508.03500},
  url = {https://arxiv.org/abs/2508.03500}
}

@misc{anonymous2025wall,
  title = {The wall confronting large language models},
  author = {Peter V. Coveney},
  year = {2025},
  eprint = {2507.19703},
  archivePrefix = {arXiv},
  primaryClass = {cs.AI},
  url = {https://arxiv.org/abs/2507.19703}
}

@misc{anonymous2025largescaleemergence,
  title = {Large Language Models and Emergence: A Complex Systems Perspective},
  author = {Giacomo De Palma and John C. Baez and Christina Lee Yu and Saeed Saremi and Jiantao Jiao and Chunyuan Li and Yuka Nikaido and Igor Razenshteyn and Pascal Vincent and Greg Yang},
  year = {2025},
  eprint = {2506.11135},
  archivePrefix = {arXiv},
  primaryClass = {cs.AI},
  doi = {10.48550/arXiv.2506.11135},
  url = {https://arxiv.org/abs/2506.11135}
}

@misc{anonymous2025olympiadmath,
  title = {Challenging the Boundaries of Reasoning: An Olympiad-Level Math Benchmark for Large Language Models},
  author = {Haoxiang Sun and Yingqian Min and Zhipeng Chen and Wayne Xin Zhao and Zheng Liu and Zhongyuan Wang and Lei Fang and Ji-Rong Wen},
  year = {2025},
  eprint = {2503.21380},
  archivePrefix = {arXiv},
  primaryClass = {cs.AI},
  doi = {10.48550/arXiv.2503.21380},
  url = {https://arxiv.org/abs/2503.21380}
}

@misc{anonymous2025varmath,
  title = {VAR-MATH: Probing True Mathematical Reasoning in Large Language Models via Symbolic Multi-Instance Benchmarks},
  author = {Jian Yao and Ran Cheng and Kay Chen Tan},
  year = {2025},
  eprint = {2507.12885},
  archivePrefix = {arXiv},
  primaryClass = {cs.AI},
  doi = {10.48550/arXiv.2507.12885},
  url = {https://arxiv.org/abs/2507.12885}
}

@misc{anonymous2025doesmath,
  title = {Does Math Reasoning Improve General LLM Capabilities? Understanding Transferability of LLM Reasoning},
  author = {Maggie Huan and Yuetai Li and Tuney Zheng and Xiaoyu Xu and Seungone Kim and Minxin Du and Radha Poovendran and Graham Neubig and Xiang Yue},
  year = {2025},
  eprint = {2507.00432},
  archivePrefix = {arXiv},
  primaryClass = {cs.AI},
  doi = {10.48550/arXiv.2507.00432},
  url = {https://arxiv.org/abs/2507.00432}
}

@misc{anonymous2025beyondaccuracy,
  title = {Beyond Accuracy: Dissecting Mathematical Reasoning for LLMs},
  author = {Jiayu Wang and Yifei Ming and Zixuan Ke and Caiming Xiong and Shafiq Joty and Aws Albarghouthi and Frederic Sala},
  year = {2025},
  eprint = {2506.04723},
  archivePrefix = {arXiv},
  primaryClass = {cs.CL},
  doi = {10.48550/arXiv.2506.04723},
  url = {https://arxiv.org/abs/2506.04723}
}

@misc{anonymous2025cama,
  title = {CAMA: Enhancing Mathematical Reasoning in Large Language Models with Causal Knowledge},
  author = {Lei Zan and Keli Zhang and Ruichu Cai and Lujia Pan},
  year = {2025},
  eprint = {2508.02583},
  archivePrefix = {arXiv},
  primaryClass = {cs.AI},
  doi = {10.48550/arXiv.2508.02583},
  url = {https://arxiv.org/abs/2508.02583}
}

@misc{anonymous2025advancingmultistep,
  title = {Advancing Multi-Step Mathematical Reasoning in Large Language Models through Multi-Layered Self-Reflection with Auto-Prompting},
  author = {—},
  year = {2025},
  eprint = {2506.23888},
  archivePrefix = {arXiv},
  primaryClass = {cs.AI},
  url = {https://arxiv.org/abs/2506.23888},
  note = {Author names to be updated; see arXiv record.}
}

@misc{anonymous2025deeptheorem,
  title = {DeepTheorem: Advancing LLM Reasoning for Theorem Proving Through Natural Language and Reinforcement Learning},
  author = {Ziyin Zhang and Jiahao Xu and Zhiwei He and Tian Liang and Qiuzhi Liu and Yansi Li and Linfeng Song and Zhenwen Liang and Zhuosheng Zhang and Rui Wang and Zhaopeng Tu and Haitao Mi and Dong Yu},
  year = {2025},
  eprint = {2505.23754},
  archivePrefix = {arXiv},
  primaryClass = {cs.CL},
  doi = {10.48550/arXiv.2505.23754},
  url = {https://arxiv.org/abs/2505.23754}
}

@misc{anonymous2025reliablemath,
  title = {ReliableMath: Benchmark of Reliable Mathematical Reasoning on Large Language Models},
  author = {Boyang Xue and Qi Zhu and Rui Wang and Sheng Wang and Hongru Wang and Fei Mi and Yasheng Wang and Lifeng Shang and Qun Liu and Kam-Fai Wong},
  year = {2025},
  eprint = {2507.03133},
  archivePrefix = {arXiv},
  primaryClass = {cs.CL},
  doi = {10.48550/arXiv.2507.03133},
  url = {https://arxiv.org/abs/2507.03133}
}

@misc{anonymous2025whoreasons,
  title = {Who Reasons in the Large Language Models?},
  author = {Yi Yang and Guang Yang and Fengzhen Lin and Shuchang Liu and Zhenyu Hou},
  year = {2025},
  eprint = {2505.20993},
  archivePrefix = {arXiv},
  primaryClass = {cs.AI},
  doi = {10.48550/arXiv.2505.20993},
  url = {https://arxiv.org/abs/2505.20993}
}

@misc{anonymous2025revisitingrl,
  title = {Revisiting Reinforcement Learning for LLM Reasoning from A Cross-Domain Perspective},
  author = {Zikun Zhao and Linyang Li and Zihao Chen and Jidong Tu and Baoshan Kan and Qipeng Guo and Xipeng Qiu},
  year = {2025},
  eprint = {2506.14965},
  archivePrefix = {arXiv},
  primaryClass = {cs.AI},
  doi = {10.48550/arXiv.2506.14965},
  url = {https://arxiv.org/abs/2506.14965}
}

@misc{anonymous2025leanconjecturer,
  title = {LeanConjecturer: Automatic Generation of Mathematical Conjectures for Theorem Proving},
  author = {Zichen Zhang and Jipeng Zhang and Albert Qiaolu He and Honghua Zhang and Xifeng Yan},
  year = {2025},
  eprint = {2506.22005},
  archivePrefix = {arXiv},
  primaryClass = {cs.AI},
  doi = {10.48550/arXiv.2506.22005},
  url = {https://arxiv.org/abs/2506.22005}
}

@misc{anonymous2025rewritingpretraining,
  title = {Rewriting Pre-Training Data Boosts LLM Performance in Math and Code},
  author = {Kazuki Fujii and Yukito Tajima and Sakae Mizuki and Hinari Shimada and Taihei Shiotani and Koshiro Saito and Masanari Ohi and Masaki Kawamura and Taishi Nakamura and Takumi Okamoto and Shigeki Ishida and Kakeru Hattori and Youmi Ma and Hiroya Takamura and Rio Yokota and Naoaki Okazaki},
  year = {2025},
  eprint = {2505.02881},
  archivePrefix = {arXiv},
  primaryClass = {cs.LG},
  doi = {10.48550/arXiv.2505.02881},
  url = {https://arxiv.org/abs/2505.02881}
}

@misc{anonymous2025polymatheval,
  title = {PolyMath: Evaluating Mathematical Reasoning in Multilingual Contexts},
  author = {Yiming Wang and Pei Zhang and Jialong Tang and Haoran Wei and Baosong Yang and Rui Wang and Chenshu Sun and Feitong Sun and Jiran Zhang and Junxuan Wu and Qiqian Cang and Yichang Zhang and Fei Huang and Junyang Lin and Jingren Zhou},
  year = {2025},
  eprint = {2504.18428},
  archivePrefix = {arXiv},
  primaryClass = {cs.CL},
  doi = {10.48550/arXiv.2504.18428},
  url = {https://arxiv.org/abs/2504.18428}
}

@misc{anonymous2025enigmata,
  title = {Enigmata: Scaling Logical Reasoning in Large Language Models with Synthetic Verifiable Puzzles},
  author = {Jiangjie Chen and Qianyu He and Siyu Yuan and Aili Chen and Zhicheng Cai and Weinan Dai and Hongli Yu and Qiying Yu and Xuefeng Li and Jiaze Chen and Hao Zhou and Mingxuan Wang},
  year = {2025},
  eprint = {2505.19914},
  archivePrefix = {arXiv},
  primaryClass = {cs.CL},
  doi = {10.48550/arXiv.2505.19914},
  url = {https://arxiv.org/abs/2505.19914}
}

@misc{anonymous2025llmthinkbench,
  title = {LLMThinkBench: Towards Basic Math Reasoning and Overthinking in Large Language Models},
  author = {Gaurav Srivastava and Aafiya Hussain and Sriram Srinivasan and Xuan Wang},
  year = {2025},
  eprint = {2507.04023},
  archivePrefix = {arXiv},
  primaryClass = {cs.CL},
  doi = {10.48550/arXiv.2507.04023},
  url = {https://arxiv.org/abs/2507.04023}
}

@misc{anonymous2025canllmstrategic,
  title = {Can Large Language Models Develop Strategic Reasoning? Post-training Insights from Learning Chess},
  author = {Dongyoon Hwang and Hojoon Lee and Jaegul Choo and Dongmin Park and Jongho Park},
  year = {2025},
  eprint = {2507.00726},
  archivePrefix = {arXiv},
  primaryClass = {cs.AI},
  doi = {10.48550/arXiv.2507.00726},
  url = {https://arxiv.org/abs/2507.00726}
}

@article{anonymous2025deepmindopenai,
  title = {DeepMind and OpenAI models solve maths problems at level of top students},
  author = {Holly Else},
  journal = {Nature},
  year = {2025},
  month = {July},
  doi = {10.1038/d41586-025-02343-x},
  url = {https://www.nature.com/articles/d41586-025-02343-x}
}

@misc{anonymous2025godelbanach,
  title = {The G{\"o}del-Banach Correspondence: Internal Undecidability from Hilbert Spaces to Derived Categories},
  author = {Paul C. Lee},
  year = {2025},
  month = {July},
  note = {Preprint}
}

@misc{kamoi2025training,
  title = {Training Step-Level Reasoning Verifiers with Formal Verification Tools},
  author = {Ryo Kamoi and others},
  year = {2025},
  month = {May},
  eprint = {2505.15960},
  archivePrefix = {arXiv},
  primaryClass = {cs.CL},
  url = {https://arxiv.org/abs/2505.15960}
}

@misc{anonymous2025warriormath,
  title = {WarriorMath: Enhancing the Mathematical Ability of Large Language Models through Self-Improvement},
  author = {Zhaokun Yang and Xinhai Chen and Yufei Geng and Yu Zhang and Bo Liu and Che Liu and Hang Dong and Gang Zhang},
  year = {2025},
  eprint = {2508.01245},
  archivePrefix = {arXiv},
  primaryClass = {cs.AI},
  doi = {10.48550/arXiv.2508.01245},
  url = {https://arxiv.org/abs/2508.01245}
}

@misc{anonymous2025enhancingmathsmall,
  title = {Enhancing Math Reasoning in Small-sized LLMs via Preview Difficulty-Aware Intervention},
  author = {Xinhan Di and JoyJiaoW},
  year = {2025},
  eprint = {2508.01604},
  archivePrefix = {arXiv},
  primaryClass = {cs.LG},
  doi = {10.48550/arXiv.2508.01604},
  url = {https://arxiv.org/abs/2508.01604}
}

@misc{anonymous2025enhancingmathreasoningllm,
  title = {Enhancing Mathematical Reasoning in Large Language Models via Preview-Based Reward Models},
  author = {Mingsheng Liu and Qingming Tang and Jiale Chen and Steve Renals},
  year = {2025},
  eprint = {2504.09440},
  archivePrefix = {arXiv},
  primaryClass = {cs.AI},
  doi = {10.48550/arXiv.2504.09440},
  url = {https://arxiv.org/abs/2504.09440}
}

@misc{anonymous2025largescaleproofs,
  title = {A Large-Scale Study of LLM-Generated Mathematical Proofs},
  author = {Jasper Dekoninck and Ivo Petrov and Kristian Minchev and Mislav Balunovi{\'c} and Martin T. Vechev and Miroslav Marinov and Maria Drencheva and Lyuba Konova and Milen Shumanov and Kaloyan Tsvetkov and Nikolay Drenchev and Lazar Todorov and Kalina Nikolova and Nikolay Georgiev and Vanesa Kalinkova and Margulan Ismoldayev},
  year = {2025},
  eprint = {2506.21621},
  archivePrefix = {arXiv},
  primaryClass = {cs.AI},
  doi = {10.48550/arXiv.2506.21621},
  url = {https://arxiv.org/abs/2506.21621}
}




@article{adarsh2024siked,
  title = {SIKeD: Self-guided iterative knowledge distillation for mathematical reasoning},
  author = {Adarsh, S and Shridhar, K and Gulcehre, C and Monath, N and Sachan, M},
  journal = {CoRR},
  volume = {abs/2410.18574},
  year = {2024}
}

@article{didolkar2024metacognitive,
  title = {Metacognitive capabilities of LLMs: An exploration in mathematical problem solving},
  author = {Didolkar, A and Goyal, A and Ke, N R and Guo, S and Valko, M and Lillicrap, T and Rezende, D and Bengio, Y and Mozer, M and Arora, S},
  journal = {CoRR},
  volume = {abs/2405.12205},
  year = {2024}
}

@article{feng2024bstep,
  title = {Step-by-step reasoning for math problems via twisted sequential monte carlo},
  author = {Feng, S and Kong, X and Ma, S and Zhang, A and Yin, D and Wang, C and Pang, R and Yang, Y},
  journal = {CoRR},
  volume = {abs/2410.01920},
  year = {2024b}
}

@article{guan2025rstar,
  title = {rStar-Math: Small LLMs can master math reasoning with self-evolved deep thinking},
  author = {Guan, X and Zhang, L L and Liu, Y and Shang, N and Sun, Y and Zhu, Y and Yang, F and Yang, M},
  journal = {CoRR},
  volume = {abs/2501.04519},
  year = {2025}
}

@article{guo2024learning,
  title = {Learning beyond pattern matching? assaying mathematical understanding in LLMs},
  author = {Guo, S and Didolkar, A and Ke, N R and Goyal, A and Huszár, F and Schölkopf, B},
  journal = {CoRR},
  volume = {abs/2405.15485},
  year = {2024}
}

@article{he2024bolympiadbench,
  title = {OlympiadBench: A challenging benchmark for promoting AGI with olympiad-level bilingual multimodal scientific problems},
  author = {He, C and Luo, R and Bai, Y and Hu, S and Thai, Z L and Shen, J and Hu, J and Han, X and Huang, Y and Zhang, Y and Liu, J and Qi, Lei and Liu, Z and Sun, Maosong},
  journal = {Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics},
  year = {2024a}
}

@article{huang2024key,
  title = {Key-point-driven data synthesis with its enhancement on mathematical reasoning},
  author = {Huang, Y and Liu, X and Gong, Y and Gou, Z and Shen, Y and Duan, N and Chen, W},
  journal = {CoRR},
  volume = {abs/2403.02333},
  year = {2024}
}

@article{li2024acommon,
  title = {Common 7b language models already possess strong math capabilities},
  author = {Li, C and Wang, W and Hu, J and Wei, Y and Zheng, N and Hu, H and Zhang, Z and Peng, H},
  journal = {CoRR},
  volume = {abs/2403.04706},
  year = {2024a}
}

@misc{li2024cnuminamath,
  title = {NuminaMath: The largest public dataset in AI4Maths with 860k pairs of competition math problems and solutions},
  author = {Li, J and Beeching, E and Tunstall, L and Lipkin, B and Soletskyi, R and Huang, S and Rasul, K and Yu, L and Jiang, A Q and Shen, Z and others},
  year = {2024c},
  note = {Hugging Face repository},
  pages = {9}
}

@article{li2024dgsmplus,
  title = {GSM-Plus: A comprehensive benchmark for evaluating the robustness of LLMs as mathematical problem solvers},
  author = {Li, Q and Cui, L and Zhao, X and Kong, L and Bi, W},
  journal = {CoRR},
  volume = {abs/2402.19255},
  year = {2024d}
}

@article{liang2023let,
  title = {Let GPT be a math tutor: Teaching math word problem solvers with customized exercise generation},
  author = {Liang, Z and Yu, W and Rajpurohit, T and Clark, P and Zhang, X and Kalyan, A},
  journal = {Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing},
  year = {2023}
}

@article{liu2023augmenting,
  title = {Augmenting math word problems via iterative question composing},
  author = {Liu, B and Bubeck, S and Eldan, R and Kulkarni, J and Li, Y and Nguyen, A and Ward, R and Zhang, Y},
  journal = {CoRR},
  volume = {abs/2312.09241},
  year = {2023}
}

@article{luo2024improve,
  title = {Improve mathematical reasoning in language models by automated process supervision},
  author = {Luo, L and Liu, Y and Liu, R and Phatale, S and Lara, H and Li, Y and Shu, L and Meng, J and Sun, Y and others},
  journal = {CoRR},
  volume = {abs/2406.06592},
  year = {2024}
}

@article{paster2024openwebmath,
  title = {OpenWebMath: An open dataset of high-quality mathematical web text},
  author = {Paster, K and Dos Santos, M and Azerbayev, Z and Ba, J},
  journal = {Proceedings of the 12th International Conference on Learning Representations},
  year = {2024}
}

@article{shao2024deepseekmath,
  title = {DeepSeekMath: Pushing the limits of mathematical reasoning in open language models},
  author = {Shao, Z and Wang, P and Zhu, Q and Xu, R and Song, J and Bi, X and Zhang, H and Zhang, M and Li, Y and Wu, Y and Guo, D},
  journal = {arXiv preprint arXiv:2402.03300},
  year = {2024}
}

@article{sprague2024ato,
  title = {To CoT or not to CoT? chain-of-thought helps mainly on math and symbolic reasoning},
  author = {Sprague, Z and Yin, F and Rodriguez, J D and Jiang, D and Wadhwa, M and Singhal, P and Zhao, X and Ye, X and Mahowald, K and Durrett, G},
  journal = {CoRR},
  volume = {abs/2409.12183},
  year = {2024a}
}

@article{sprague2024bto,
  title = {To CoT or not to CoT? chain-of-thought helps mainly on math and symbolic reasoning},
  author = {Sprague, Z and Yin, F and Rodriguez, J D and Jiang, D and Wadhwa, M and Singhal, P and Zhao, X and Ye, X and Mahowald, K and Durrett, G},
  journal = {CoRR},
  volume = {abs/2409.12183},
  year = {2024b}
}

@article{srivastava2024evaluating,
  title = {Evaluating LLMs’ mathematical reasoning in financial document question answering},
  author = {Srivastava, P and Malik, M and Ganu, T and Roth, D},
  journal = {Findings of the Association for Computational Linguistics},
  year = {2024}
}

@article{toshniwal2024aopenmathinstruct2,
  title = {OpenMathInstruct-2: Accelerating AI for math with massive open-source instruction data},
  author = {Toshniwal, S and Du, W and Moshkov, I and Kisacanin, B and Ayrapetyan, A and Gitman, I},
  journal = {CoRR},
  volume = {abs/2410.01560},
  year = {2024a}
}

@article{toshniwal2024bopenmathinstruct1,
  title = {OpenMathInstruct-1: A 1.8 million math instruction tuning dataset},
  author = {Toshniwal, S and Moshkov, I and Narenthiran, S and Gitman, D and Jia, F and Gitman, I},
  journal = {Advances in Neural Information Processing Systems 38},
  year = {2024b}
}

@article{wang2024dalpha,
  title = {AlphaMath almost zero: Process supervision without process},
  author = {Wang, L and Li, L and Shao, Z and Xu, R and Dai, D and Li, Y and Chen, D and Wu, Y and Sui, Z},
  journal = {Advances in Neural Information Processing Systems 38},
  year = {2024d}
}

@article{wei2023cmath,
  title = {CMATH: can your language model pass chinese elementary school math test?},
  author = {Wei, T and Luan, J and Liu, W and Dong, S and Wang, B},
  journal = {CoRR},
  volume = {abs/2306.16636},
  year = {2023}
}

@article{yan2024survey,
  title = {A survey of mathematical reasoning in the era of multimodal large language model: Benchmark, method & challenges},
  author = {Yan, Y and Su, J and He, J and Fu, F and Zheng, X and Lyu, K and Wang, S and Wang, Q and Wen, H and Hu, X},
  journal = {CoRR},
  volume = {abs/2412.11936},
  year = {2024}
}

@article{ye2024physics,
  title = {Physics of language models: Part 2.2, how to learn from mistakes on grade-school math problems},
  author = {Ye, T and Xu, Z and Li, Y and Allen-Zhu, Z},
  journal = {CoRR},
  volume = {abs/2408.16293},
  year = {2024}
}

@article{ying2024binternlm,
  title = {InternLM-Math: Open math large language models toward verifiable reasoning},
  author = {Ying, H and Zhang, S and Li, L and Zhou, Z and Shao, Y and Fei, Z and Ma, Y and Hong, J and Liu, K and Wang, Z and others},
  journal = {CoRR},
  volume = {abs/2402.06332},
  year = {2024b}
}

@article{yue2024amammoth,
  title = {MAmmoTH: Building math generalist models through hybrid instruction tuning},
  author = {Yue, X and Qu, X and Zhang, G and Fu, Y and Huang, W and Sun, Y and Su, Y and Chen, W},
  journal = {Proceedings of the 12th International Conference on Learning Representations},
  year = {2024a}
}

@article{yue2024bmammoth2,
  title = {Mammoth2: Scaling instructions from the web},
  author = {Yue, X and Zheng, T and Zhang, G and Chen, W},
  journal = {CoRR},
  volume = {abs/2405.03548},
  year = {2024b}
}

@article{zhong2024achieving,
  title = {Achieving >97% on GSM8K: Deeply understanding the problems makes LLMs better reasoners},
  author = {Zhong, Q and Wang, K and Xu, Z and Liu, J and Ding, L and Farajtabar, M and Tao, Y and Shen, D},
  journal = {CoRR},
  volume = {abs/2404.14963},
  year = {2024}
}

@article{zhou2024jiuzhang30,
  title = {JiuZhang3.0: Efficiently improving mathematical reasoning by training small data synthesis models},
  author = {Zhou, K and Zhang, B and Wang, J and Chen, W X and Zhao, Z and Sha, J and Sheng, Z and Wang, Q and Wen, J-R},
  journal = {CoRR},
  volume = {abs/2405.14365},
  year = {2024}
}




@article{ahn2024,
  author = {Ahn, Janice and Verma, Rishu and Lou, Renze and Liu, Di and Zhang, Rui and Yin, Wenpeng},
  title = {Large language models for mathematical reasoning: Progresses and challenges},
  journal = {arXiv preprint arXiv:2402.00157},
  year = {2024}
}

@article{chen2024a,
  author = {Chen, Changyu and Wang, Xiting and Lin, Ting-En and Lv, Ang and Wu, Yuchuan and Gao, Xin and Wen, Ji-Rong and Yan, Rui and Li, Yongbin},
  title = {Masked thought: Simply masking partial reasoning steps can improve mathematical reasoning learning of language models},
  journal = {arXiv preprint arXiv:2403.02178},
  year = {2024}
}

@article{chen2025a,
  author = {Chen, Feng and Raventos, Allan and Cheng, Nan and Ganguli, Surya and Druckmann, Shaul},
  title = {Rethinking fine-tuning when scaling test-time compute: Limiting confidence improves mathematical reasoning},
  journal = {arXiv preprint arXiv:2502.07154},
  year = {2025}
}

@article{chernyshev2024,
  author = {Chernyshev, Konstantin and Polshkov, Vitaliy and Artemova, Ekaterina and Myasnikov, Alex and Stepanov, Vlad and Miasnikov, Alexei and Tilga, Sergei},
  title = {U-math: A university-level benchmark for evaluating mathematical skills in llms},
  journal = {arXiv preprint arXiv:2412.03205},
  year = {2024}
}

@article{deng2023,
  author = {Deng, Shumin and Zhang, Ningyu and Oo, Nay and Hooi, Bryan},
  title = {Towards a unified view of answer calibration for multi-step reasoning},
  journal = {arXiv preprint arXiv:2311.09101},
  year = {2023}
}

@article{fang2024,
  author = {Fang, Meng and Wan, Xiangpeng and Lu, Fei and Xing, Fei and Zou, Kai},
  title = {MathOdyssey: Benchmarking mathematical problem-solving skills in large language models using odyssey math data},
  journal = {arXiv preprint arXiv:2406.18321},
  year = {2024}
}

@article{feng2024,
  author = {Feng, Shengyu and Kong, Xiang and Ma, Shuang and Zhang, Aonan and Yin, Dong and Wang, Chong and Pang, Ruoming and Yang, Yiming},
  title = {Step-by-step reasoning for math problems via twisted sequential monte carlo},
  journal = {arXiv preprint arXiv:2410.01920},
  year = {2024}
}

@article{gao2023,
  author = {Gao, Jiahui and Pi, Renjie and Zhang, Jipeng and Ye, Jiacheng and Zhong, Wanjun and Wang, Yufei and Hong, Lanqing and Han, Jianhua and Xu, Hang and Li, Zhenguo and others},
  title = {G-LLaVA: Solving geometric problem with multi-modal large language model},
  journal = {arXiv preprint arXiv:2312.11370},
  year = {2023}
}

@article{gou2023,
  author = {Gou, Zhibin and Shao, Zhihong and Gong, Yeyun and Shen, Yelong and Yang, Yujiu and Huang, Minlie and Duan, Nan and Chen, Weizhu},
  title = {ToRA: A tool-integrated reasoning agent for mathematical problem solving},
  journal = {arXiv preprint arXiv:2309.17452},
  year = {2023}
}

@article{guo2024a,
  author = {Guo, Siyuan and Didolkar, Aniket and Ke, Nan Rosemary and Goyal, Anirudh and Huszár, Ferenc and Schölkopf, Bernhard},
  title = {Learning beyond pattern matching? Assaying mathematical understanding in LLMs},
  journal = {arXiv preprint arXiv:2405.15485},
  year = {2024}
}

@article{gupta2024,
  author = {Gupta, Himanshu and Verma, Shreyas and Anantheswaran, Ujjwala and Scaria, Kevin and Parmar, Mihir and Mishra, Swaroop and Baral, Chitta},
  title = {PolyMath: A challenging multi-modal mathematical reasoning benchmark},
  journal = {arXiv preprint arXiv:2410.14702},
  year = {2024}
}

@article{han2024,
  author = {Han, Xiaotian and Jian, Yiren and Hu, Xuefeng and Liu, Haogeng and Wang, Yiqi and Fan, Qihang and Ai, Yuang and Huang, Huaibo and He, Ran and Yang, Zhenheng and You, Quanzeng},
  title = {InfiMM-WebMath-40B: Advancing Multimodal Pre-Training for Enhanced Mathematical Reasoning},
  journal = {arXiv preprint arXiv:2409.12568},
  year = {2024}
}

@article{he2024,
  author = {He, Chaoqun and Luo, Renjie and Bai, Yuzhuo and Hu, Shengding and Thai, Zhen Leng and Shen, Junhao and Hu, Jinyi and Han, Xu and Huang, Yujie and Zhang, Yuxiang and Liu, Jie and Qi, Lei and Liu, Zhiyuan and Sun, Maosong},
  title = {OlympiadBench: A challenging benchmark for promoting AGI with olympiad-level bilingual multimodal scientific problems},
  journal = {arXiv preprint arXiv:2402.14008},
  year = {2024}
}

@article{huang2024c,
  author = {Huang, Yiming and Liu, Xiao and Gong, Yeyun and Gou, Zhibin and Shen, Yelong and Duan, Nan and Chen, Weizhu},
  title = {Key-point-driven data synthesis with its enhancement on mathematical reasoning},
  journal = {arXiv preprint arXiv:2403.02333},
  year = {2024}
}

@article{jia2024,
  author = {Jia, Mengzhao and Zhang, Zhihan and Yu, Wenhao and Jiao, Fangkai and Jiang, Meng},
  title = {Describe-then-reason: Improving multimodal mathematical reasoning through visual comprehension training},
  journal = {arXiv preprint arXiv:2404.14604},
  year = {2024}
}

@article{kang2024,
  author = {Kang, Jikun and Li, Xin Zhe and Chen, Xi and Kazemi, Amirreza and Sun, Qianyi and Chen, Boxing and Li, Dong and He, Xu and He, Quan and Wen, Feng and others},
  title = {MindStar: Enhancing math reasoning in pre-trained LLMs at inference time},
  journal = {arXiv preprint arXiv:2405.16265},
  year = {2024}
}

@article{kazemi2023,
  author = {Kazemi, Mehran and Alvari, Hamidreza and Anand, Ankit and Wu, Jialin and Chen, Xi and Soricut, Radu},
  title = {GeomVerse: A systematic evaluation of large models for geometric reasoning},
  journal = {arXiv preprint arXiv:2312.12241},
  year = {2023}
}

@article{kim2023,
  author = {Kim, JB and Kim, Hazel and Hahn, Joonghyuk and Han, Yo-Sub},
  title = {Athena: Mathematical reasoning with thought expansion},
  journal = {arXiv preprint arXiv:2311.01036},
  year = {2023}
}

@article{kurtic2024,
  author = {Kurtic, Eldar and Moeini, Amir and Alistarh, Dan},
  title = {Mathador-LM: A dynamic benchmark for mathematical reasoning on large language models},
  journal = {arXiv preprint arXiv:2406.12572},
  year = {2024}
}

@article{lei2024,
  author = {Lei, Bin and Zhang, Yi and Zuo, Shan and Payani, Ali and Ding, Caiwen},
  title = {Macm: Utilizing a multi-agent system for condition mining in solving complex mathematical problems},
  journal = {arXiv preprint arXiv:2404.04735},
  year = {2024}
}

@article{liang2023a,
  author = {Liang, Zhenwen and Yang, Tianyu and Zhang, Jipeng and Zhang, Xiangliang},
  title = {UniMath: A foundational and multimodal mathematical reasoner},
  journal = {Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing},
  pages = {7126--7133},
  year = {2023}
}

@article{liang2023b,
  author = {Liang, Zhenwen and Yu, Dian and Pan, Xiaoman and Yao, Wenlin and Zeng, Qingkai and Zhang, Xiangliang and Yu, Dong},
  title = {MINT: Boosting generalization in mathematical reasoning via multi-view fine-tuning},
  journal = {arXiv preprint arXiv:2307.07951},
  year = {2023}
}

@article{liang2024c,
  author = {Liang, Zhenwen and Yu, Dian and Yu, Wenhao and Yao, Wenlin and Zhang, Zhihan and Zhang, Xiangliang and Yu, Dong},
  title = {MathChat: Benchmarking mathematical reasoning and instruction following in multi-turn interactions},
  journal = {arXiv preprint arXiv:2405.19444},
  year = {2024}
}

@article{liu2024b,
  author = {Liu, Hongwei and Zheng, Zilong and Qiao, Yuxuan and Duan, Haodong and Fei, Zhiwei and Zhou, Fengzhe and Zhang, Wenwei and Zhang, Songyang and Lin, Dahua and Chen, Kai},
  title = {MathBench: Evaluating the theory and application proficiency of LLMs with a hierarchical mathematics benchmark},
  journal = {arXiv preprint arXiv:2405.12209},
  year = {2024}
}

@article{liu2025,
  author = {Liu, MingShan and Bo, Shi and Fang, Jialing},
  title = {Enhancing mathematical reasoning in large language models with self-consistency-based hallucination detection},
  journal = {arXiv preprint arXiv:2504.09440},
  year = {2025}
}

@article{liu2023b,
  author = {Liu, Wentao and Hu, Hanglei and Zhou, Jie and Ding, Yuyang and Li, Junsong and Zeng, Jiayi and He, Mengliang and Chen, Qin and Jiang, Bo and Zhou, Aimin and others},
  title = {Mathematical language models: A survey},
  journal = {arXiv preprint arXiv:2312.07622},
  year = {2023}
}

@article{lu2024b,
  author = {Lu, Zimu and Zhou, Aojun and Ren, Houxing and Wang, Ke and Shi, Weikang and Pan, Junting and Zhan, Mingjie and Li, Hongsheng},
  title = {MathGenie: Generating synthetic data with question back-translation for enhancing mathematical reasoning of LLMs},
  journal = {arXiv preprint arXiv:2402.16352},
  year = {2024}
}

@article{lu2024c,
  author = {Lu, Zimu and Zhou, Aojun and Wang, Ke and Ren, Houxing and Shi, Weikang and Pan, Junting and Zhan, Mingjie and Li, Hongsheng},
  title = {MathCoder2: Better math reasoning from continued pretraining on model-translated mathematical code},
  journal = {Preprint, arXiv:2410.08196},
  year = {2024}
}

@article{luo2023,
  author = {Luo, Haipeng and Sun, Qingfeng and Xu, Can and Zhao, Pu and Lou, Jianguang and Tao, Chongyang and Geng, Xiubo and Lin, Qingwei and Chen, Shifeng and Zhang, Dongmei},
  title = {WizardMath: Empowering mathematical reasoning for large language models via reinforced evol-instruct},
  journal = {arXiv preprint arXiv:2308.09583},
  year = {2023}
}

@article{mao2024,
  author = {Mao, Yujun and Kim, Yoon and Zhou, Yilun},
  title = {CHAMP: A competition-level dataset for fine-grained analyses of LLMs’ mathematical reasoning capabilities},
  journal = {arXiv preprint arXiv:2401.06961},
  year = {2024}
}

@article{mirzadeh2024,
  author = {Mirzadeh, Iman and Alizadeh, Keivan and Shahrokhi, Hooman and Tuzel, Oncel and Bengio, Samy and Farajtabar, Mehrdad},
  title = {GSM-Symbolic: Understanding the limitations of mathematical reasoning in large language models},
  journal = {arXiv preprint arXiv:2410.05229},
  year = {2024}
}

@article{poesia2024,
  author = {Poesia, Gabriel and Broman, David and Haber, Nick and Goodman, Noah D},
  title = {Learning formal mathematics from intrinsic motivation},
  journal = {arXiv preprint arXiv:2407.00695},
  year = {2024}
}

@article{shao2024,
  author = {Shao, Zhihong and Wang, Peiyi and Zhu, Qihao and Xu, Runxin and Song, Junxiao and Bi, Xiao and Zhang, Haowei and Zhang, Mingchuan and Li, Yikang and Wu, Y and Guo, Daya},
  title = {DeepSeekMath: Pushing the limits of mathematical reasoning in open language models},
  journal = {arXiv preprint arXiv:2402.03300},
  year = {2024}
}

@article{shi2024,
  author = {Shi, Wenhao and Hu, Zhiqiang and Bin, Yi and Liu, Junhua and Yang, Yang and Ng, See-Kiong and Bing, Lidong and Lee, Roy Ka-Wei},
  title = {Math-LLaVA: Bootstrapping mathematical reasoning for multimodal large language models},
  journal = {arXiv preprint arXiv:2406.17294},
  year = {2024}
}

@article{toshniwal2024a,
  author = {Toshniwal, Shubham and Du, Wei and Moshkov, Ivan and Kisacanin, Branislav and Ayrapetyan, Alexan and Gitman, Igor},
  title = {OpenMathInstruct-2: Accelerating AI for math with massive open-source instruction data},
  journal = {arXiv preprint arXiv:2410.01560},
  year = {2024}
}

@article{toshniwal2024b,
  author = {Toshniwal, Shubham and Moshkov, Ivan and Narenthiran, Sean and Gitman, Daria and Jia, Fei and Gitman, Igor},
  title = {OpenMathInstruct-1: A 1.8 million math instruction tuning dataset},
  journal = {arXiv preprint arXiv:2402.10176},
  year = {2024}
}

@article{wang2024c,
  author = {Wang, Peiyi and Li, Lei and Shao, Zhihong and Xu, Runxin and Dai, Damai and Li, Yifei and Chen, Deli and Wu, Yu and Sui, Zhifang},
  title = {Math-Shepherd: Verify and reinforce LLMs step-by-step without human annotations},
  journal = {Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  pages = {9426--9439},
  year = {2024}
}

@article{yan2024a,
  author = {Yan, Yibo and Wang, Shen and Huo, Jiahao and Li, Hang and Li, Boyan and Su, Jiamin and Gao, Xiong and Zhang, Yi-Fan and Xu, Tianlong and Chu, Zhendong and others},
  title = {ErrorRadar: Benchmarking complex mathematical reasoning of multimodal large language models via error detection},
  journal = {arXiv preprint arXiv:2410.04509},
  year = {2024}
}

@article{yan2025b,
  author = {Yan, Yibo and Wang, Shen and Huo, Jiahao and Yu, Philip S and Hu, Xuming and Wen, Qingsong},
  title = {MathAgent: Leveraging a mixture-of-math-agent framework for real-world multimodal mathematical error detection},
  journal = {arXiv preprint arXiv:2503.18132},
  year = {2025}
}

@article{yang2024a,
  author = {Yang, An and Zhang, Beichen and Hui, Binyuan and Gao, Bofei and Yu, Bowen and Li, Chengpeng and Liu, Dayiheng and Tu, Jianhong and Zhou, Jingren and Lin, Junyang and others},
  title = {Qwen2.5-Math Technical Report: Toward Mathematical Expert Model via Self-Improvement},
  journal = {arXiv preprint arXiv:2409.12122},
  year = {2024}
}

@article{yang2024b,
  author = {Yang, Zhen and Chen, Jinhao and Du, Zhengxiao and Yu, Wenmeng and Wang, Weihan and Hong, Wenyi and Jiang, Zhihuan and Xu, Bin and Dong, Yuxiao and Tang, Jie},
  title = {MathGLM-Vision: Solving mathematical problems with multi-modal large language model},
  journal = {arXiv preprint arXiv:2409.13729},
  year = {2024}
}

@article{yang2023b,
  author = {Yang, Zhen and Ding, Ming and Lv, Qingsong and Jiang, Zhihuan and He, Zehai and Guo, Yuyi and Bai, Jinfeng and Tang, Jie},
  title = {GPT can solve mathematical problems without a calculator},
  journal = {arXiv preprint arXiv:2309.03241},
  year = {2023}
}

@article{yue2023,
  author = {Yue, Xiang and Qu, Xingwei and Zhang, Ge and Fu, Yao and Huang, Wen-hao and Sun, Huan and Su, Yu and Chen, Wenhu},
  title = {Mammoth: Building math generalist models through hybrid instruction tuning},
  journal = {arXiv preprint arXiv:2309.05653},
  year = {2023}
}

@article{yue2024c,
  author = {Yue, Xiang and Zheng, Tuney and Zhang, Ge and Chen, Wenhu},
  title = {Mammoth2: Scaling instructions from the web},
  journal = {arXiv preprint arXiv:2405.03548},
  year = {2024}
}

@article{zeng2024,
  author = {Zeng, Liang and Zhong, Liangjun and Zhao, Liang and Wei, Tianwen and Yang, Liu and He, Jujie and Cheng, Cheng and Hu, Rui and Liu, Yang and Yan, Shuicheng and others},
  title = {Skywork-Math: Data scaling laws for mathematical reasoning in large language models–the story goes on},
  journal = {arXiv preprint arXiv:2407.08348},
  year = {2024}
}

@article{zhang2024d,
  author = {Zhang, Jiaxin and Li, Zhongzhi and Zhang, Mingliang and Yin, Fei and Liu, Chenglin and Moshfeghi, Yashar},
  title = {GeoEval: benchmark for evaluating LLMs and multi-modal models on geometry problem-solving},
  journal = {arXiv preprint arXiv:2402.10104},
  year = {2024}
}

@article{zhou2024a,
  author = {Zhou, Kun and Zhang, Beichen and Wang, Jiapeng and Chen, Wayne X and Zhao, Zhipeng and Sha, Jing and Sheng, Zhichao and Wang, Qian and Wen, Ji-Rong},
  title = {JiuZhang 3.0: Efficiently improving mathematical reasoning by training small data synthesis models},
  journal = {arXiv preprint arXiv:2405.14365},
  year = {2024}
}

@article{zhuang2024,
  author = {Zhuang, Wenwen and Huang, Xin and Zhang, Xiantao and Zeng, Jin},
  title = {Math-PUMA: Progressive upward multimodal alignment to enhance mathematical reasoning},
  journal = {arXiv preprint arXiv:2408.08640},
  year = {2024}
}


@misc{chen2025seedproverdeepbroadreasoning,
      title={Seed-Prover: Deep and Broad Reasoning for Automated Theorem Proving}, 
      author={Luoxin Chen and Jinming Gu and Liankai Huang and Wenhao Huang and Zhicheng Jiang and Allan Jie and Xiaoran Jin and Xing Jin and Chenggang Li and Kaijing Ma and Cheng Ren and Jiawei Shen and Wenlei Shi and Tong Sun and He Sun and Jiahui Wang and Siran Wang and Zhihong Wang and Chenrui Wei and Shufa Wei and Yonghui Wu and Yuchen Wu and Yihang Xia and Huajian Xin and Fan Yang and Huaiyuan Ying and Hongyi Yuan and Zheng Yuan and Tianyang Zhan and Chi Zhang and Yue Zhang and Ge Zhang and Tianyun Zhao and Jianqiu Zhao and Yichi Zhou and Thomas Hanwen Zhu},
      year={2025},
      eprint={2507.23726},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2507.23726}, 
}

@misc{perez2025ai4mathnativespanishbenchmark,
      title={AI4Math: A Native Spanish Benchmark for University-Level Mathematical Reasoning in Large Language Models}, 
      author={Miguel Angel Peñaloza Perez and Bruno Lopez Orozco and Jesus Tadeo Cruz Soto and Michelle Bruno Hernandez and Miguel Angel Alvarado Gonzalez and Sandra Malagon},
      year={2025},
      eprint={2505.18978},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2505.18978}, 
}

@misc{chen2024enhancingmathematicalreasoningllms,
      title={Enhancing Mathematical Reasoning in LLMs with Background Operators}, 
      author={Jiajun Chen and Yik-Cheung Tam},
      year={2024},
      eprint={2412.04110},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2412.04110}, 
}